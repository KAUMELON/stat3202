[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"\n\nWelcome book LECTURE NOTES STATISTICAL METHODS APPLICATIONS.","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"\n\nNote: book published MeLoN (Module e-Learning & Online Notes) . online version book free read .\n\nfeedback, please feel free contact Dr.Pratheesh P. Gopinath. E-mail: pratheesh.pg@kau.Thank !\n\nbook collection lecture notes covering syllabus statistics course B.Sc.(Hons.) Agriculture Kerala Agricultural University\n","code":""},{"path":"introduction.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"lecture introduction, includes, definition statistics, collection classification data, formation frequency distribution.(Goon Dasgupta 1983) (Gupta Kapoor 1997)","code":""},{"path":"introduction.html","id":"origin-of-the-word-statistics","chapter":"1 Introduction","heading":"1.1 Origin of the word ‚ÄúStatistics‚Äù","text":"term statistics derived Neo-Latin word statisticum collegium meaning ‚Äúcouncil state‚Äù Italian word statista meaning ‚Äústatesman‚Äù ‚Äúpolitician.‚Äù\nFigure 1.1: Statistical Account Scotland Sir John Sinclair (1791)\n","code":""},{"path":"introduction.html","id":"statistics-and-mathematics","chapter":"1 Introduction","heading":"1.2 Statistics and Mathematics","text":"Mathematics follows rigid theorem proof. Mathematical theories involve well-defined proven facts minimal scope change. However, Statistics discipline real-life data handled. factor makes field study abstract, individuals develop newer solutions problems new observed . Statistics applied science; mathematics goal prove theorems. statistics, main goal develop good methods understanding data making decisions. Statisticians often use mathematical theorems justify methods, theorems main focus. Statistics now considered independent field uses mathematics solve real life problems.","code":""},{"path":"introduction.html","id":"definition-of-statistics","chapter":"1 Introduction","heading":"1.3 Definition of Statistics","text":"Statistics science deals theCollection dataCollection dataOrganization data Classification dataOrganization data Classification dataPresentation dataPresentation dataAnalysis dataAnalysis dataInterpretation dataInterpretation dataTwo main branches statistics :Descriptive statistics, deals summarizing data sample using indexes mean standard deviation etc.Inferential statistics, use random sample data taken population describe make inferences population parameters.","code":""},{"path":"introduction.html","id":"data","chapter":"1 Introduction","heading":"1.4 Data","text":"Data can defined individual pieces factual information recorded used purpose analysis. raw information inferences drawn using science ‚ÄúSTATISTICS.‚ÄùExample dataNo.¬†farmers block..¬†farmers block.rainfall period time.rainfall period time.Area paddy crop state.Area paddy crop state.","code":""},{"path":"introduction.html","id":"use-and-limitations-of-statistics","chapter":"1 Introduction","heading":"1.5 Use and limitations of statistics","text":"Functions statistics: Statistics simplifies complexity, presents facts definite form, helps formulation suitable policies, facilitates comparison helps forecasting. Valid results conclusion obtained research experiments using proper statistical tools.Uses statistics: Statistics pervaded almost spheres human activities. Statistics useful administration, Industry, business, economics, research workers, banking,insurance companies etc.Limitations StatisticsStatistical theories can applied variability experimental material.Statistical theories can applied variability experimental material.Statistics deals aggregates groups individual objects.Statistics deals aggregates groups individual objects.Statistical results exact.Statistical results exact.Statistics often misused.Statistics often misused.","code":""},{"path":"introduction.html","id":"population-and-sample","chapter":"1 Introduction","heading":"1.6 Population and Sample","text":"Consider following example.Suppose wish study body masses students College Agriculture, Vellayani. take us long time measure body masses students college may select 20 students measure body masses (kg). Suppose obtain measurements like this49 56 48 61 59 43 58 52 64 71 57 52 63 58 51 47 57 46 53 59In study, interested body masses students College Agriculture, Vellayani. set body masses students College Agriculture, Vellayani called population study. set 20 body masses, W = {49, 56,48, ‚Ä¶, 53, 59}, sample population.","code":""},{"path":"introduction.html","id":"population","chapter":"1 Introduction","heading":"1.6.1 Population","text":"population set objects wish study","code":""},{"path":"introduction.html","id":"sample","chapter":"1 Introduction","heading":"1.6.2 Sample","text":"sample part population study learn population.","code":""},{"path":"introduction.html","id":"variables-and-constants","chapter":"1 Introduction","heading":"1.7 Variables and constants","text":"","code":""},{"path":"introduction.html","id":"variables","chapter":"1 Introduction","heading":"1.7.1 Variables","text":"type observation can take different values different people, different values different times, places, called variable. following examples variables:family size, number hospital beds, number schools country, etc.family size, number hospital beds, number schools country, etc.height, mass, blood pressure, temperature, blood glucose level, etc.height, mass, blood pressure, temperature, blood glucose level, etc.Broadly speaking, two types variables ‚Äì quantitative qualitative (categorical) variables","code":""},{"path":"introduction.html","id":"constants","chapter":"1 Introduction","heading":"1.7.2 Constants","text":"Constants characteristics values change. Examples constants : pi (ùùÖ) = ratio circumference circle diameter (ùùÖ = 3.14159...) e, base natural (Napierian) logarithms (e=2.71828).","code":""},{"path":"introduction.html","id":"types-of-variables","chapter":"1 Introduction","heading":"1.8 Types of variables","text":"","code":""},{"path":"introduction.html","id":"quantitative-variables","chapter":"1 Introduction","heading":"1.8.1 Quantitative variables","text":"quantitative variable one can take numerical values. variables like family size, number hospital beds, number schools country, height, mass, blood pressure, temperature, blood glucose level, etc. examples quantitative variables. Quantitative variables may characterized whether \ndiscrete continuous","code":""},{"path":"introduction.html","id":"discrete-variables","chapter":"1 Introduction","heading":"1.8.2 Discrete variables","text":"variables like family size, number hospital beds, number schools country, etc. can counted. examples discrete variables. Variables can take finite number values called \"discrete variables.\" variable phrased ‚Äúnumber ‚Ä¶,‚Äù discrete, possible list possible\nvalues {0,1, ‚Ä¶}. variable finite number possible values discrete. following example illustrates point. number daily admissions hospital discrete variable since can represented whole number, 0, 1, 2 3. number daily\nadmissions given day number 1.8, 3.96 5.33.","code":""},{"path":"introduction.html","id":"continuous-variables","chapter":"1 Introduction","heading":"1.8.3 Continuous variables","text":"variables like height, mass, blood pressure, temperature, blood glucose level, etc. can measured. examples continuous variables. continuous variable possess gaps interruptions characteristic discrete variable. continuous\nvariable can assume value within specific relevant interval values assumed variable. Notice age continuous since individual age discrete jumps. Weight can measured 35.5, 35.8 kg etc , continuous variable.","code":""},{"path":"introduction.html","id":"categorical-variables","chapter":"1 Introduction","heading":"1.8.4 Categorical variables","text":"variable called categorical measurement scale set categories. example, marital status, categories (single,married, widowed), categorical. Whether employed (yes, ), religious affiliation (Protestant, Catholic, Jewish, Muslim, others, none),\ncolours etc. Categorical variables often called qualitative. can seen categorical variables can neither measured counted.","code":""},{"path":"introduction.html","id":"measurement-scales","chapter":"1 Introduction","heading":"1.9 Measurement scales","text":"Variables can classified according following four levels measurement: nominal, ordinal, interval ratio.","code":""},{"path":"introduction.html","id":"nominal-scale","chapter":"1 Introduction","heading":"1.9.1 Nominal scale","text":"scale measure applies qualitative variables . nominal scale, order required. example,gender nominal, blood group nominal, marital status also nominal. perform arithmetic operations data measured nominal scale.","code":""},{"path":"introduction.html","id":"ordinal-scale","chapter":"1 Introduction","heading":"1.9.2 Ordinal scale","text":"scale also applies qualitative data. \nordinal scale, order necessary. means one category lower next one vice versa. example, Grades ordinal, excellent higher good, turn higher good, . noted , ordinal scale, differences category values meaning.","code":""},{"path":"introduction.html","id":"interval-scale","chapter":"1 Introduction","heading":"1.9.3 Interval scale","text":"scale measurement applies quantitative\ndata . scale, zero point indicate total absence quantity measured. example scale temperature Celsius Fahrenheit scale. Suppose minimum temperatures 3 cities, , B C, particular day 00C, 200C 100C, respectively. clear can find differences temperatures. example, city B 200C hotter city . However, say city temperature. Moreover, say city B twice hot city C, just city B 200C city C 100C. reason , interval scale, ratio two numbers meaningful.","code":""},{"path":"introduction.html","id":"ratio-scale","chapter":"1 Introduction","heading":"1.9.4 Ratio scale","text":"scale measurement also applies quantitative\ndata properties interval scale. addition properties, ratio scale meaningful zero starting point meaningful ratio 2 numbers. example variables measured ratio scale, weight. weighing scale reads 0 kg\ngives indication absolutely weight . zero starting point meaningful. Ram weighs 40 kg Laxman weighs 20 kg, Ram weighs twice Laxman. Another example variable measured ratio scale temperature measured Kelvin scale. true zero point.\nFigure 1.2: Classification variables\n","code":""},{"path":"introduction.html","id":"collection-of-data","chapter":"1 Introduction","heading":"1.10 Collection of Data","text":"first step enquiry (investigation) collection data. data may collected whole population sample . mostly collected sample basis. Collecting data difficult job. enumerator investigator well trained individual collects statistical data. respondents persons information collected.","code":""},{"path":"introduction.html","id":"types-of-data","chapter":"1 Introduction","heading":"1.10.1 Types of Data","text":"two types (sources) collection data:\n* Primary Data\n* Secondary Data","code":""},{"path":"introduction.html","id":"primary-data","chapter":"1 Introduction","heading":"1.10.1.1 Primary Data","text":"Primary data first hand information collected, compiled published organizations purpose. original data character undergone sort statistical treatment.Example: Population census reports primary data collected, complied published population census organization.","code":""},{"path":"introduction.html","id":"secondary-data","chapter":"1 Introduction","heading":"1.10.1.2 Secondary Data","text":"secondary data second hand information already collected organization purpose available present study. Secondary data pure character undergone treatment least .Example: economic survey England secondary data data collected one organization like Bureau Statistics, Board Revenue, banks, etc.","code":""},{"path":"introduction.html","id":"methods-of-collecting-primary-data","chapter":"1 Introduction","heading":"1.11 Methods of Collecting Primary Data","text":"Primary data collected using following methods:","code":""},{"path":"introduction.html","id":"personal-investigation","chapter":"1 Introduction","heading":"1.11.1 Personal Investigation","text":"researcher conducts survey /collects data . data collected way usually accurate reliable. method collecting data \napplicable case small research projects.","code":""},{"path":"introduction.html","id":"through-investigation","chapter":"1 Introduction","heading":"1.11.2 Through Investigation","text":"Trained investigators employed collect data. investigators contact individuals fill \nquestionnaires asking required information. organizations utilize method.","code":""},{"path":"introduction.html","id":"collection-through-questionnaire","chapter":"1 Introduction","heading":"1.11.3 Collection through Questionnaire","text":"Researchers get data local representations agents based upon experience. method quick gives rough estimate.","code":""},{"path":"introduction.html","id":"through-the-telephone","chapter":"1 Introduction","heading":"1.11.4 Through the Telephone","text":"Researchers get information individuals telephone. method quick gives accurate information.","code":""},{"path":"introduction.html","id":"methods-of-collecting-secondary-data","chapter":"1 Introduction","heading":"1.12 Methods of Collecting Secondary Data","text":"Secondary data collected following methods:","code":""},{"path":"introduction.html","id":"official","chapter":"1 Introduction","heading":"1.12.1 Official","text":"Publications Statistical Division, Ministry Finance, Federal Bureaus Statistics, Ministries Food, Agriculture, Industry, Labor, etc.","code":""},{"path":"introduction.html","id":"semi-official","chapter":"1 Introduction","heading":"1.12.2 Semi-Official","text":"Publications State Bank, Railway Board, Central Cotton Committee, Boards Economic Enquiry etc.Publication Trade Associations, Chambers Commerce, etc.Technical Trade Journals Newspapers.Research Organizations universities institutions.","code":""},{"path":"introduction.html","id":"difference-between-primary-and-secondary-data","chapter":"1 Introduction","heading":"1.13 Difference Between Primary and Secondary Data","text":"difference primary secondary data change hand. Primary data first hand information directly collected form one source. original character undergone sort statistical treatment, secondary data obtained sources agencies. pure character undergone treatment least .","code":""},{"path":"introduction.html","id":"frequency-distribution","chapter":"1 Introduction","heading":"1.14 Frequency distribution","text":"\nFigure 1.3: raw data set .¬†children 54 families\n\nFigure 1.4: Frequency distribution table\nNow certain features data become apparent. instance, can easily seen , 54 families selected two children number houses 2 children 18. information easily obtained raw data. table called frequency table frequency distribution. called gives frequency number times \nobservation occurs. Thus, finding frequency observation, intelligible picture obtained.","code":""},{"path":"introduction.html","id":"construction-of-frequency-distribution","chapter":"1 Introduction","heading":"1.14.1 Construction of frequency distribution","text":"List values variable ascending order magnitude.List values variable ascending order magnitude.Form tally column, , value data, record stroke tally column next value. tally, fifth stroke made across first four. makes easy count entries enter frequency observation.Form tally column, , value data, record stroke tally column next value. tally, fifth stroke made across first four. makes easy count entries enter frequency observation.Check frequencies sum total number observationsCheck frequencies sum total number observations","code":""},{"path":"introduction.html","id":"grouped-frequency-distribution","chapter":"1 Introduction","heading":"1.15 Grouped frequency distribution","text":"Data gives body masses 22 patients, measured nearest kilogram.\nFigure 1.5: Body masses 22 patients\ncan seen minimum maximum body masses 42 kg 83 kg, respectively. frequency distribution giving every body mass 42 kg 83 kg long informative. problem overcome grouping data classes.\nchoose classes\n41 ‚Äì 49\n50 ‚Äì 58\n59 ‚Äì 67\n68 ‚Äì 76\n77 ‚Äì 85, obtain frequency distribution given :\nFigure 1.6: Grouped Frequency distribution table\ntable gives frequency group class; therefore called grouped frequency table grouped frequency distribution. Using grouped frequency distribution, easier obtain information data using raw data. instance, can seen 17 22 patients body masses 50 kg 76 kg (inclusive). information easily obtained raw data.\nnoted , even though table concise, information lost. example, grouped frequency distribution give us exact body masses patients. Thus individual body masses patients lost effort obtain overall picture.","code":""},{"path":"introduction.html","id":"terms-used-in-grouped-frequency-tables.","chapter":"1 Introduction","heading":"1.16 Terms used in grouped frequency tables.","text":"Class limitsThe intervals observations put called class intervals. end points class intervals called class limits. example, class interval 41 ‚Äì 49, lower class limit 41 upper class limit 49.Class boundariesThe raw data example recorded nearest kilogram. Thus, body mass 49.5kg recorded 50 kg, body mass 58.4 kg recorded 58 kg, body mass 58.5 kg recorded 59 kg. can therefore seen\n, class interval 50 ‚Äì 58, consists measurements greater equal 49.5 kg less 58.5 kg. numbers 49.5 58.5 called lower upper boundaries class interval 50 ‚Äì 58. class boundaries class intervals given :\nFigure 1.7: Class boundary class limits\nNote:\nNotice lower class boundary ith class interval mean lower class limit class interval upper class limit (-1)th class interval (= 2, 3, 4, ‚Ä¶). example, table lower class boundaries second fourth class intervals (50 + 49) /2 = 49.5 (68 + 67)/2 = 67.5 respectively.\ncan also seen upper class boundary ith class interval mean upper class limit class interval lower class limit (+1)th class interval (= 1, 2, 3, ‚Ä¶). Thus, table upper class boundary fourth class\ninterval (76 + 77)/2 = 76.5.Class mark\nmid-point class interval called class mark class mid-point class interval. average upper lower class limits class interval. also average upper lower class boundaries class interval. example, table, class mark third class interval found \nfollows: class mark =(59+67) /2 = (58.5 + 67.5)/2= 63.Class width\ndifference upper lower class boundaries class interval called class width class interval. Class widths class intervals can also found subtracting two consecutive lower class limits, subtracting two consecutive upper class limits.Note:width ith class interval numerical difference upper class limits ith ( -1)th class intervals (= 2, 3, ‚Ä¶). also numerical difference lower class limits ith (+1) th class intervals (= 1, 2, ‚Ä¶).grouped frequency table width first class interval |41-50| = 9. numerical difference lower class limits first second class intervals. width second class interval |50-59|= 9. numerical difference lower class limits second third\nclass intervals. also equal |58-49| numerical, difference upper class limits first second class intervals.","code":""},{"path":"introduction.html","id":"construction-of-frequency-distribution-table","chapter":"1 Introduction","heading":"1.17 Construction of frequency distribution table","text":"Step 1. Decide many classes wish use.Step 2. Determine class widthStep 3. Set individual class limits\nStep 4. Tally items classesStep 5. Count number items classConsider example\nagricultural student measured lengths leaves oak tree (nearest cm). Measurements 38 leaves follows\n9,16,13,7,8,4,18,10,17,18,9,12,5,9,9,16,1,8,17,1,10,5,9,11,15,6,14,9,1,12,5,16,4,16,8,15,14,17Step 1. Decide many classes wish use.H.. Sturges provides formula determining approximation number classes. \\(\\mathbf{k = 1 + 3.322}\\mathbf{\\log}\\mathbf{N}\\). Number classes greater calculated k\nexample N=38, k=1+3.322√ólog(38) = 1+3.322√ó1.5797 = 6.24 = approx 7So approximated number classes less 6.24 .e.\\(\\ k^{'}\\) =7Step 2. Determine class widthGenerally, class width size classes. C= | max ‚àí min|/ k. Class width \\(C^{'}\\)greater calculated C. example, C = | 18‚àí 1|/6.24 = 2.72, approximately class width\\(C^{'} =\\) 3 (Note k used calculated value using Struges formula approximated).Step 3. set individual class limits, need find lower limit \\[L = min - \\frac{C^{'} \\times k^{'} - (max - min)}{2}\\]C k final approximated class width number classes respectively example \\(L = 1 - \\frac{3 \\times 7 - (18 - 1)}{2}\\)=1-2=-1; since negative values data = 0.Even though student measured whole numbers, data continuous, \"4 cm\" means actual value anywhere 3.5 cm 4.5 cm.","code":""},{"path":"introduction.html","id":"cumulative-frequency","chapter":"1 Introduction","heading":"1.18 Cumulative frequency","text":"many situations, interested number observations given class interval, number observations less (greater ) specified value. example, table, can seen 3 leaves length less 3.5 cm 9\nleaves (.e.¬†3 + 6) length less 6.5 cm. frequencies called cumulative frequencies. table cumulative frequencies called cumulative frequency table cumulative frequency distribution.Cumulative frequency defined running total frequencies. Cumulative frequency can also defined sum previous frequencies current point. Notice last cumulative frequency equal sum frequencies. Two types cumulative frequencies Less cumulative frequency Greater cumulative frequency. Less cumulative frequency\n(LCF) number values less specified value. Greater cumulative frequency (GCF) number observations greater specified value.specified value LCF case grouped frequency\ndistribution upper limits GCF lower limits classes. LCF‚Äôs obtained adding frequencies successive classes GCF obtained subtracting successive class frequencies total frequency.","code":""},{"path":"introduction.html","id":"relative-frequency","chapter":"1 Introduction","heading":"1.19 Relative frequency","text":"sometimes useful know proportion, rather number, values falling within particular class interval. obtain information dividing frequency particular class interval total number observations. Relative frequency class\nfrequency class / total observation. Relative frequencies add 1.[1] ‚ÄúNote: = Less cumulative frequency; B= Greater cumulative frequency, C = Relative frequency‚Äù¬†\n¬†\n¬†Data sword 21st century, wield well, Samurai.‚Äù - Jonathan Rosenberg, former Google SVP!","code":""},{"path":"graphical-representation-of-data.html","id":"graphical-representation-of-data","chapter":"2 Graphical representation of data","heading":"2 Graphical representation of data","text":"found information given frequency distribution easier interpret raw data. Information given frequency distribution tabular form easier grasp presented graphically. Many types diagrams used statistics, depending nature data purpose diagram intended.","code":""},{"path":"graphical-representation-of-data.html","id":"histogram","chapter":"2 Graphical representation of data","heading":"2.1 Histogram","text":"histogram consists rectangles :Bases horizontal axis, centres class marks, lengths equal class widths.Bases horizontal axis, centres class marks, lengths equal class widths.Areas proportional class frequencies.Areas proportional class frequencies.Note:\nclass intervals equal size, heights rectangles proportional class frequencies customary take heights rectangles numerically equal class frequencies. class intervals different widths, \nheights rectangles proportional \\(\\frac{\\text{Class Frequency}}{\\text{Class Width}}\\). ratio called frequency density.Table shows frequency distribution body masses 50 AIDS patients. Draw Histogram.\nFigure 2.1: Histogram\n","code":""},{"path":"graphical-representation-of-data.html","id":"cumulative-frequency-curve-ogive","chapter":"2 Graphical representation of data","heading":"2.2 Cumulative frequency curve (Ogive)","text":"graph obtained plotting cumulative frequency class boundary joining points smooth curve, called cumulative frequency curve. also called Ogive. Two types ogive , Less Type Cumulative Frequency Curve (Less Ogive) Greater Type Cumulative Frequency Curve (Greater Ogive).","code":""},{"path":"graphical-representation-of-data.html","id":"less-than-ogive","chapter":"2 Graphical representation of data","heading":"2.2.1 Less than Ogive","text":"Also known less type cumulative frequency curve. use upper limit classes less cumulative frequency plot curve. Let us see example body masses 50 AIDS patients.\nFigure 2.2: Less ogive\n","code":""},{"path":"graphical-representation-of-data.html","id":"greater-than-ogive","chapter":"2 Graphical representation of data","heading":"2.2.2 Greater than Ogive","text":"Also known greater type cumulative frequency curve use lower limit classes greater cumulative frequency plot curve.\nFigure 2.3: greater ogive\nNote:\nIntersection ogives gives median","code":""},{"path":"graphical-representation-of-data.html","id":"frequency-polygon","chapter":"2 Graphical representation of data","heading":"2.2.3 Frequency polygon","text":"grouped frequency table can also represented frequency\npolygon, special kind line graph. construct frequency\npolygon, plot graph class frequencies corresponding\nclass mid-points join successive points straight lines. Frequency polygon also obtained joining midpoints histogram shown Fig 2.5.\nFigure 2.4: Frequency polygon\n\nFigure 2.5: Frequency polygon histogram\n","code":""},{"path":"graphical-representation-of-data.html","id":"stem-and-leaf-plot","chapter":"2 Graphical representation of data","heading":"2.3 Stem-and-leaf plot","text":"stem--leaf plot graphical device useful representing relatively small set data takes numerical values. construct stem--leaf plot, partition measurement two parts. first part called stem, second part called leaf. numerical value divided two parts:\nleading digits become stem trailing digits become leaf. One advantage stem--leaf display frequency distribution retain value observation. Another distribution data within groups clear. stem--leaf plot conveys similar information histogram. Turned side, shape histogram. fact, since \nstem--leaf plot shows observation,displays information lost histogram. properly\nconstructed stem--leaf plot, like histogram, provides information regarding range data set, shows location highest concentration measurements, reveals presence absence symmetry.Consider example10,15,22,25,28,23,29,31,36,45,48stem leaf plot can drawn shown .\nFigure 2.6: Stem Leaf plot\n","code":""},{"path":"graphical-representation-of-data.html","id":"bar-chart","chapter":"2 Graphical representation of data","heading":"2.4 Bar chart","text":"bar chart bar graph diagram consisting series horizontal vertical bars equal width. bars represent various categories data. three types bar charts, simple bar charts, component bar charts grouped bar charts.","code":""},{"path":"graphical-representation-of-data.html","id":"simple-bar-chart","chapter":"2 Graphical representation of data","heading":"2.4.1 Simple bar chart","text":"simple bar chart, height (length) bar equal value category y-axis represents. example data shows production timber five districts Kerala certain year.\nFigure 2.7: Barchart\n","code":""},{"path":"graphical-representation-of-data.html","id":"component-bar-chart","chapter":"2 Graphical representation of data","heading":"2.4.2 Component bar chart","text":"component bar chart, bar category subdivided component parts; hence name. Component bar charts therefore used show division items components. illustrated following example.Example shows distribution sales agricultural produce Farm 1995, 1996 1997.\nFigure 2.8: Sales data agricultural produce\n\nFigure 2.9: Component bar chart\ncomponent bar chart shows changes component years well comparison total sales different years.","code":""},{"path":"graphical-representation-of-data.html","id":"grouped-bar-chart","chapter":"2 Graphical representation of data","heading":"2.4.3 Grouped bar chart","text":"grouped bar chart, components grouped together drawn side side. illustrate example.\nFigure 2.10: Grouped bar chart\n","code":""},{"path":"graphical-representation-of-data.html","id":"histogram-and-bar-chart","chapter":"2 Graphical representation of data","heading":"2.5 Histogram and Bar chart","text":"","code":""},{"path":"graphical-representation-of-data.html","id":"pie-charts","chapter":"2 Graphical representation of data","heading":"2.6 Pie Charts","text":"pie chart circular graph divided sectors, sector representing different value category. angle sector pie chart proportional value part data represents. bar chart precise pie chart visual comparison categories similar relative frequencies.","code":""},{"path":"graphical-representation-of-data.html","id":"steps-for-constructing-a-pie-chart","chapter":"2 Graphical representation of data","heading":"2.6.1 Steps for constructing a pie chart","text":"Find sum category values.Calculate angle sector category, using following formula.Angle sector category = \\(\\frac{\\text{value category }}{\\text{sum category values}} \\times 360\\)Construct circle mark centre.Use protractor divide circle sectors, using angles obtained step 2.Label sector clearly.See example:\nlady spent following sums money buying ingredients family Christmas cake.\nFigure 2.11: Pie chart\n¬†\n¬†\n¬†Statistics grammar science.\" - Karl Pearson!","code":""},{"path":"measures-of-central-tendency---i.html","id":"measures-of-central-tendency---i","chapter":"3 Measures of central tendency - I","heading":"3 Measures of central tendency - I","text":"previous lecture, learnt data can summarised \nform tables presented form graphs important\nfeatures can illustrated easily effectively. \nLecture, consider statistical measures can used describe\ncharacteristics set data.interested single value serves representative\nvalue overall data. ¬†measure central tendency¬†\nsummary statistic represents centre point typical value \ndataset.five averages. Among mean, median mode called\nsimple averages two averages geometric mean harmonic\nmean called special averages. measures reflect numerical\nvalues centre set data therefore called measures\ncentral tendency.Requisites Good Measure Central Tendency:rigidly defined.rigidly defined.simple understand & easy calculateIt simple understand & easy calculateIt based upon values given dataIt based upon values given dataIt capable mathematical treatment.capable mathematical treatment.sampling stability.sampling stability.unduly affected extreme valuesIt unduly affected extreme valuesThe main objectives Measure Central TendencyTo condense data single value.condense data single value.facilitate comparisons data.facilitate comparisons data.","code":""},{"path":"measures-of-central-tendency---i.html","id":"arithmetic-mean","chapter":"3 Measures of central tendency - I","heading":"3.1 Arithmetic Mean","text":"people usually intend say \"average\". Arithmetic\nmean simply mean variable defined sum \nobservations divided number observations. Mean set \nnumbers \\(x_{1\\ },x_{2},\\ldots,x_{n}\\) denoted \\(\\overline{x}\\). \ngiven formula\\[\\overline{x} = \\frac{x_{1} + x_{2} + \\ldots + x_{n}}{n}\\]\\(= \\frac{1}{n}\\sum_{= 1}^{n}x_{}\\)Example 3.1 Find mean numbers 2, 4, 7, 8, 11, 12\\[\\overline{x} = \\frac{2 + 4 + 7 + 8 + 11 + 12}{6} = \\frac{44}{6} = 7.33\\]","code":""},{"path":"measures-of-central-tendency---i.html","id":"the-mean-of-a-frequency-distribution","chapter":"3 Measures of central tendency - I","heading":"3.1.1 The mean of a frequency distribution","text":"","code":""},{"path":"measures-of-central-tendency---i.html","id":"direct-method","chapter":"3 Measures of central tendency - I","heading":"3.1.1.1 Direct method","text":"numbers \\(x_{1\\ },x_{2},\\ldots,x_{n}\\) occur frequencies\n\\(f_{1\\ },f_{2},\\ldots,f_{n}\\) respectively \\[\\overline{x} = \\frac{x_{1}f_{1} + x_{2}f_{2\\ \\ } + \\ldots + x_{n}f_{n}}{f_{1} + f_{2} + \\ldots f_{n}}\\]\\[= \\frac{\\sum_{= 1}^{n}{f_{}x_{}}}{\\sum_{= 1}^{n}f_{}}\\]Example 3.2 Table shows body masses 50 men. Find \nmean body mass.Table 3.1:  Body masses 50 men.Solution 3.2The calculation can arranged shown\\(\\overline{x} = \\frac{\\sum_{= 1}^{n}{f_{}x_{}}}{\\sum_{= 1}^{n}f_{}} = \\frac{3054}{50}\\)=\n61.08 kg","code":""},{"path":"measures-of-central-tendency---i.html","id":"assumed-mean-method-indirect-method","chapter":"3 Measures of central tendency - I","heading":"3.1.1.2 Assumed mean method (Indirect method)","text":"amount computation involved can reduced using \nfollowing formula:\\[\\overline{x} = + \\frac{\\sum_{= 1}^{n}{f_{}d_{}}}{\\sum_{= 1}^{n}f_{}}\\]\\(\\) assumed mean, can value x.\n\\(d_{} = x_{} - \\), \\(f_{}\\) frequency \\(x_{}\\)Consider Example 2.2 see Table: 3.1let \\(\\) = 61; can number x\\(\\overline{x} = 61 + \\frac{4}{50}\\) = 61.08 kgThe mean mass 61.08 kg","code":""},{"path":"measures-of-central-tendency---i.html","id":"mean-of-grouped-data","chapter":"3 Measures of central tendency - I","heading":"3.1.2 Mean of Grouped Data","text":"","code":""},{"path":"measures-of-central-tendency---i.html","id":"direct-method-1","chapter":"3 Measures of central tendency - I","heading":"3.1.2.1 Direct method","text":"mean grouped data obtained following formula:\\[\\overline{x} = \\frac{\\sum_{= 1}^{k}{f_{}x_{}}}{n}\\]\\(x_{}\\) = mid-point ith class (ith class mark);\n\\(f_{}\\)= frequency ith class; \\(n\\) = sum \nfrequencies total frequencies sample. Note =1,2...,\nk, .e. k classes.Example 3.3 Shows distribution marks scored 60 students Physics examination. Find mean mark.Table 3.2:  Distribution marks scored 60 studentsSolution 3.3The solution can arranged shown\\(\\overline{x} = \\frac{\\sum_{= 1}^{n}{f_{}x_{}}}{\\sum_{= 1}^{n}f_{}} = \\frac{4365}{60}\\)=\n72.75The mean mark 72.75%","code":""},{"path":"measures-of-central-tendency---i.html","id":"coding-method-indirect-method","chapter":"3 Measures of central tendency - I","heading":"3.1.2.2 Coding method (Indirect method)","text":"class intervals grouped frequency distribution equal size \\(C\\) (class width); following formula can used instead direct method . formula makes calculations easier.\\[\\overline{x} = + C\\frac{\\sum_{= 1}^{n}{f_{}u_{}}}{\\sum_{= 1}^{n}f_{}}\\]\\(\\) class mark highest frequency,\n\\(u_{} = \\frac{x_{} - }{C}\\), \\(f_{}\\) frequency \\(x_{}\\), C\nclass widthThis called ‚Äúcoding‚Äù method computing mean. short method always used finding mean grouped frequency distribution equal class widths.Consider Example 3.3 see Table:3.2\\(\\)=72.5, class mark highest frequency; \\(C\\) =5\\(\\overline{x} = 72.5 + 5 \\times \\left( \\frac{3}{60} \\right)\\)= 72.75The mean mark 72.75%","code":""},{"path":"measures-of-central-tendency---i.html","id":"merits-and-demerits-of-arithmetic-mean-merits","chapter":"3 Measures of central tendency - I","heading":"3.2 Merits and demerits of Arithmetic mean Merits","text":"Merits rigidly defined.rigidly defined.easy understand easy calculate.easy understand easy calculate.number items sufficiently large, accurate\nreliable.number items sufficiently large, accurate\nreliable.calculated value based position \nseries.calculated value based position \nseries.possible calculate even details data\nlacking.possible calculate even details data\nlacking.averages, affected least fluctuations sampling.averages, affected least fluctuations sampling.provides good basis comparison.provides good basis comparison.DemeritsIt obtained inspection located frequency\ngraph.obtained inspection located frequency\ngraph.study qualitative phenomena capable \nnumerical measurement .e. Intelligence, beauty, honesty etc.study qualitative phenomena capable \nnumerical measurement .e. Intelligence, beauty, honesty etc.can ignore single item risk losing \naccuracy.can ignore single item risk losing \naccuracy.affected much extreme values.affected much extreme values.calculated open-end classes.calculated open-end classes.may lead fallacious conclusions, details data\ncomputed given.may lead fallacious conclusions, details data\ncomputed given.","code":""},{"path":"measures-of-central-tendency---i.html","id":"the-median","chapter":"3 Measures of central tendency - I","heading":"3.3 The median","text":"median set data defined middle value \ndata arranged order magnitude. ties, half \nobservations smaller median, half \nobservations larger median. median can \nmiddle item divides group two equal parts, one part\ncomprising values greater, , values less \nitem. positional measure.","code":""},{"path":"measures-of-central-tendency---i.html","id":"median-of-ungrouped-or-raw-data","chapter":"3 Measures of central tendency - I","heading":"3.3.1 Median of ungrouped or raw data","text":"Arrange given n observations \\(x_{1\\ },x_{2},\\ldots,x_{n}\\) \nascending order. number values odd, median middle\nvalue. number values even, median mean middle two\nvalues.Arrange data ascending use following formulaWhen n odd, Median = Md\n=\\(\\left( \\frac{n + 1}{2} \\right)^{\\text{th}}\\)valueWhen n even, Median = Md\n=\\({\\text{Average\\ \\ }\\left( \\frac{n}{2} \\right)^{th}\\text{\\ }\\left( \\frac{n}{2} + 1 \\right)}^{\\text{th}}\\)valueExample 3.4 Find median following sets \nnumbers.() 12, 15, 22, 17, 20, 26, 22, 26, 12(b) 4, 7, 9, 10, 5, 1, 3, 4, 12, 10Solution 3.4() Arranging data increasing order magnitude, \nobtain 12, 12, 15, 17, 20, 22, 22, 26, 26. , N (= 9) odd, ,\nmedian =\\(\\left( \\frac{9 + 1}{2} \\right)^{\\text{th}}\\)= 5th ordered\nobservation = 20.Note: number repeated, still count number times \nappears calculate median.(b) Arranging data increasing order magnitude, obtain\n1, 3, 4, 4, 5, 7, 9, 10, 10, 12. , N(=10) even number \nmedian = \\(\\frac{1}{2}\\){5th ordered observation + 6th ordered\nobservation} = \\(\\frac{1}{2}\\left( 5 + 7 \\right) = 6\\).Note: can see case, median divides distribution \ntwo equal parts, 50% observations greater \n50% less .","code":""},{"path":"measures-of-central-tendency---i.html","id":"median-of-ungrouped-frequency-distribution","chapter":"3 Measures of central tendency - I","heading":"3.3.2 Median of ungrouped frequency distribution","text":"median middle number ordered set data. \nfrequency table, observations already arranged ascending\norder. can obtain median looking value middle\nposition.","code":""},{"path":"measures-of-central-tendency---i.html","id":"median-of-a-frequency-table-when-the-number-of-observations-is-odd","chapter":"3 Measures of central tendency - I","heading":"3.3.2.1 Median of a frequency table when the number of observations is odd","text":"number observations (n) odd, median value\n¬†\\(\\left( \\frac{n + 1}{2} \\right)^{\\text{th}}\\) positional value.\nuse less cumulative frequency.Example 3.5: following frequency table score obtained mathematics quiz. Find median score.Table 3.3:  Score obtained mathematics quiz.Solution 3.5:Total frequency = 3 + 4 + 7 + 6 + 3 = 23 (odd number). Since number\nscores odd, median \n\\(\\left( \\frac{23 + 1}{2} \\right)^{\\text{th}} =\\) 12th¬†position. find\n12th¬†position, use less cumulative frequencies \nshown:12th¬†position 7th¬†position \n14th¬†position. , median 2.","code":""},{"path":"measures-of-central-tendency---i.html","id":"median-of-a-frequency-table-when-the-number-of-observations-is-even","chapter":"3 Measures of central tendency - I","heading":"3.3.2.2 Median of a frequency table when the number of observations is even","text":"number observations even, median average\n\n\\({\\left( \\frac{n}{2} \\right)^{th}\\text{\\ }\\left( \\frac{n}{2} + 1 \\right)}^{\\text{th}}\\)\nposition values.Example 3.6: table frequency table marks obtained competition. Find median score.Table 3.4:  Distribution marks obtained competition.Solution 3.6:Total frequency = 11 + 9 + 5 + 10 + 15 = 50 (even number). Since \nnumber scores even, median average ¬†values \n\\({\\left( \\frac{n}{2} \\right)^{th} = 25\\ \\ \\left( \\frac{n}{2} + 1 \\right)}^{\\text{th}} = 26\\)\npositions. find 25th¬†position 26th¬†position, add frequencies shown:mark 25th¬†position 2 mark 26th¬†position\n3. median average scores 25th¬†\n26th¬†positions =¬†\\(\\frac{2 + 3}{2} = 2.5\\)","code":""},{"path":"measures-of-central-tendency---i.html","id":"median-of-grouped-frequency-distribution","chapter":"3 Measures of central tendency - I","heading":"3.3.3 Median of grouped frequency distribution","text":"exact value median grouped data obtained\nactual values grouped data known. grouped\nfrequency distribution, median class interval \ncontains \\(\\left( \\frac{N}{2} \\right)^{\\text{th}}\\)ordered\nobservation, \\(N\\) total number observations. class\ninterval called median class. median grouped\nfrequency distribution can estimated either following two\nmethods:","code":""},{"path":"measures-of-central-tendency---i.html","id":"linear-interpolation-method-for-estimating-the-median","chapter":"3 Measures of central tendency - I","heading":"3.3.3.1 Linear interpolation method for estimating the median","text":"median grouped frequency distribution can estimated \nlinear interpolation. assume observations evenly spread\nmedian class. median can computed using \nfollowing formula:\\[median = L + \\left( \\frac{\\frac{1}{2}N - F}{f_{m}} \\right)C\\]\\(N\\) = total number observations, \\(L\\) = lower limit \nmedian class, \\(F\\) = sum frequencies L(cumulative\nfrequency), \\(f_{m}\\) = frequency median class, \\(C\\) = class width\nmedian class.","code":""},{"path":"measures-of-central-tendency---i.html","id":"estimation-of-the-median-from-a-cumulative-frequency-curve","chapter":"3 Measures of central tendency - I","heading":"3.3.3.2 Estimation of the median from a cumulative frequency curve","text":"\nFigure 3.1: median cumulative frequency curve\nExample 3.7 Table gives distribution heights 60\nstudents Senior High school. Find median height studentsTable 3.5: Distribution heights 60\nstudentsSolution 3.7() Linear interpolation method estimating median\\(N\\) = 60Median class= class interval contains \n\\(\\left( \\frac{N}{2} \\right)^{\\text{th}}\\)ordered observation; \n\\(\\left( \\frac{60}{2} \\right)^{\\text{th}} =\\) 30th observation. \nclass 160-165 3+9+16=28 observations 30th observation\nclass 160-165, therefore median class.\\(L\\) = lower limit median class =160\\(F\\) = sum frequencies 160(cumulative frequency) = 16+9+3=\n28\\(f_{m}\\) = frequency median class=18\\(C\\) = class width median class=5\\(median = 160 + \\left( \\frac{\\frac{1}{2}60 - 28}{18} \\right)5\\) = 160.56(ii) Estimation median cumulative frequency curve\nFigure 3.2: Median cumulative frequency curve Example 3.7\n","code":""},{"path":"measures-of-central-tendency---i.html","id":"merits-and-demerits-of-median","chapter":"3 Measures of central tendency - I","heading":"3.4 Merits and Demerits of Median","text":"MeritsMedian influenced extreme values \npositional average.Median influenced extreme values \npositional average.Median can calculated case distribution open-end\nintervalsMedian can calculated case distribution open-end\nintervalsMedian can located even data incomplete.Median can located even data incomplete.DemeritsA slight change series may bring drastic change median\nvalue.slight change series may bring drastic change median\nvalue.case even number items continuous series, median \nestimated value value series.case even number items continuous series, median \nestimated value value series.suitable mathematical treatment except use\ncalculating mean deviation.suitable mathematical treatment except use\ncalculating mean deviation.take account observationsIt take account observations","code":""},{"path":"measures-of-central-tendency---i.html","id":"the-mode","chapter":"3 Measures of central tendency - I","heading":"3.5 The mode","text":"mode set data value occurs greatest\nfrequency. mode therefore common value. mode \nimportant measure case qualitative data. mode can used \ndescribe quantitative qualitative data.","code":""},{"path":"measures-of-central-tendency---i.html","id":"mode-of-ungrouped-or-raw-data","chapter":"3 Measures of central tendency - I","heading":"3.5.1 Mode of ungrouped or raw data","text":"ungrouped data series individual observations, mode often\nfound mere inspection.Example 3.8() mode 1, 2, 2, 2, 3 2.(b) modes 2, 3, 4, 4, 5, 5 4 5.(c) mode exist every observation frequency. example, following sets data modes: () 3,\n6, 8, 9; (ii) 4, 4, 4, 7, 7, 7, 9, 9, 9.Note: can seen mode distribution may exist, \neven exists, may unique. Distributions single\nmode referred unimodal. Distributions two modes \nreferred bimodal. Distributions may several modes, \ncase referred multimodal.Example 3.9 20 patients selected random blood groups\ndetermined. results given table belowTable 3.6:  Blood groups 20 patientsThe blood group highest frequency O. mode data \ntherefore blood group O. can say patients selected\nblood group O. Notice mean median \napplied data. variable ‚Äúblood group‚Äù \ntake numerical values. However, can seen mode can used\ndescribe quantitative qualitative data.","code":""},{"path":"measures-of-central-tendency---i.html","id":"mode-of-grouped-frequency-distribution","chapter":"3 Measures of central tendency - I","heading":"3.5.2 Mode of Grouped frequency distribution","text":"\\[mode = L + \\left( \\frac{f_{s}}{f_{p} + f_{s}} \\right)C\\]Locate highest frequency class corresponding frequency\ncalled modal class.\\(L\\) = lower limit model class; \\(f_{p}\\)= frequency \nclass preceding model class; \\(f_{s}\\)= frequency class\nsucceeding model class \\(C\\) = class intervalExample 3.10 frequency distribution weights sorghum\near-heads given table . Calculate mode.Table 3.7: requency distribution weights sorghum ear headsModal class 100-120\\(mode = 100 + \\left( \\frac{35}{38 + 35} \\right)20 =\\) 109.589","code":""},{"path":"measures-of-central-tendency---i.html","id":"mode-using-histogram","chapter":"3 Measures of central tendency - I","heading":"3.5.3 Mode using Histogram","text":"\nFigure 3.3: Median cumulative frequency curve Example 3.10\n","code":""},{"path":"measures-of-central-tendency---i.html","id":"merits-and-demerits-of-mode","chapter":"3 Measures of central tendency - I","heading":"3.6 Merits and Demerits of Mode","text":"MeritsIt readily comprehensible easy compute. case \ncan computed merely inspection.readily comprehensible easy compute. case \ncan computed merely inspection.affected extreme values. can obtained even \nextreme values known.affected extreme values. can obtained even \nextreme values known.Mode can determined distributions open classes.Mode can determined distributions open classes.Mode can located graph also.Mode can located graph also.Mode can used describe quantitative qualitative data.Mode can used describe quantitative qualitative data.DemeritsThe mode unique. , can one mode \ngiven set data.mode unique. , can one mode \ngiven set data.mode set data may existThe mode set data may existIt based upon observation.based upon observation.¬†\n¬†\n¬†statistics boring, ‚Äôve got wrong numbers!","code":""},{"path":"measures-of-central-tendency--ii.html","id":"measures-of-central-tendency--ii","chapter":"4 Measures of central tendency -II","heading":"4 Measures of central tendency -II","text":"","code":""},{"path":"measures-of-central-tendency--ii.html","id":"geometric-mean","chapter":"4 Measures of central tendency -II","heading":"4.1 Geometric mean","text":"geometric mean type average, usually used growth rates,\nlike population growth interest rates. arithmetic mean adds\nitems, geometric mean multiplies items.geometric mean series containing n observations \nnth root product values. \n\\(x_{1},\\ x_{2},\\ldots,\\ x_{n}\\ \\)observations \\[\\mathbf{\\text{Geometric mean}}\\mathbf{,\\ }\\mathbf{GM =}\\sqrt[\\mathbf{n}]{\\mathbf{x}_{\\mathbf{1}}\\mathbf{x}_{\\mathbf{2}}\\mathbf{\\ldots}\\mathbf{x}_{\\mathbf{n}}}\\]\\[\\mathbf{=}\\left( \\mathbf{x}_{\\mathbf{1}}\\mathbf{x}_{\\mathbf{2}}\\mathbf{\\ldots}\\mathbf{x}_{\\mathbf{n}} \\right)^{\\frac{\\mathbf{1}}{\\mathbf{n}}}\\]\\[\\mathbf{\\log}\\mathbf{\\text{GM}}\\mathbf{=}\\frac{\\mathbf{1}}{\\mathbf{n}}\\mathbf{\\log}\\left( \\mathbf{x}_{\\mathbf{1}}\\mathbf{x}_{\\mathbf{2}}\\mathbf{\\ldots}\\mathbf{x}_{\\mathbf{n}} \\right)\\]\\[\\mathbf{=}\\frac{\\mathbf{1}}{\\mathbf{n}}\\left( \\mathbf{\\log}\\mathbf{x}_{\\mathbf{1}}\\mathbf{+}\\mathbf{\\log}\\mathbf{x}_{\\mathbf{2}}\\mathbf{\\ldots +}\\mathbf{\\log}\\mathbf{x}_{\\mathbf{n}} \\right)\\]\\[\\mathbf{=}\\frac{\\sum_{\\mathbf{= 1}}^{\\mathbf{n}}{\\mathbf{\\log}\\mathbf{x}_{\\mathbf{}}}}{\\mathbf{n}}\\]\\[\\mathbf{\\ GM = Antilog}\\left( \\frac{\\sum_{\\mathbf{= 1}}^{\\mathbf{n}}{\\mathbf{\\log}\\mathbf{x}_{\\mathbf{}}}}{\\mathbf{n}} \\right)\\]","code":""},{"path":"measures-of-central-tendency--ii.html","id":"geometric-mean-for-grouped-frequency-table-data","chapter":"4 Measures of central tendency -II","heading":"4.1.1 Geometric mean for grouped frequency table data","text":"\\[\\mathbf{GM = \\ Antilog}\\left( \\frac{\\sum_{\\mathbf{= 1}}^{\\mathbf{k}}{{\\mathbf{f}_{\\mathbf{}}\\mathbf{\\log}}\\mathbf{x}_{\\mathbf{}}}}{\\mathbf{n}} \\right)\\]\\(x_{}\\) mid-value, \\(f_{}\\) frequency , k \nnumber classesExample 4.1: weight sorghum ear heads 45, 60, 48,100,\n65 gms. Find Geometric mean?Solution 4.1:n =5Geometric mean=\\[\\text{Antilog}\\left( \\frac{\\sum_{= 1}^{n}{\\log x_{}}}{n} \\right) =\\]\\[Antilog\\left( \\frac{8.926}{5} \\right) =\\]\\[ Antilog(1.785) = 60.95\\]\n(note: \\(\\text{Antilog}\\left( x \\right) = 10^{x}\\) .e.\n\\[\\text{Antilog}\\left( 1.785 \\right) = \\ 10^{1.785} = 60.95\\]Example 4.2: Geometric mean Frequency DistributionSolution 4.2:\nn =32\\[GM = \\ Antilog\\left( \\frac{\\sum_{= 1}^{k}{{f_{}\\log}x_{}}}{n} \\right)\\]\\[{\\sum_{= 1}^{k}{{f_{}\\log}x_{}} = 57.782\n}\\]\\[{\\text{GM} = \\ Antilog\\left( \\frac{57.782}{32} \\right)  }\\]\\[{= Antilog\\left( 1.8056 \\right)= 10^{1.8056} = 63.92}\\]\nExample 4.3: Geometric mean Grouped Frequency DistributionSolution 4.4:\nn =32\\[GM = \\ Antilog\\left( \\frac{\\sum_{= 1}^{k}{{f_{}\\log}x_{}}}{n} \\right)\\]\\[{\\sum_{= 1}^{k}{{f_{}\\log}x_{}} = 65.787}\\]\n\\[{\\text{GM} = \\ Antilog\\left( \\frac{65.787}{32} \\right)}\\]\n\\[{= Antilog\\left( 2.0558 \\right) = 10^{2.0558} = 113.72}\\]","code":""},{"path":"measures-of-central-tendency--ii.html","id":"merits-and-demerits-of-geometric-mean","chapter":"4 Measures of central tendency -II","heading":"4.2 Merits and Demerits of Geometric mean","text":"MeritsIt rigidly defined.rigidly defined.based observations series.based observations series.suitable measuring relative changes.suitable measuring relative changes.gives weights small values less weight \nlarge values.gives weights small values less weight \nlarge values.used averaging ratios, percentages determining\nrate gradual increase decrease.used averaging ratios, percentages determining\nrate gradual increase decrease.capable algebraic treatment.capable algebraic treatment.DemeritsIt easy understand.easy understand.difficult calculate.difficult calculate.calculated, number negative values odd.calculated, number negative values odd.calculated, value series zero.calculated, value series zero.times gives value may found series \nimpractical.times gives value may found series \nimpractical.","code":""},{"path":"measures-of-central-tendency--ii.html","id":"harmonic-mean","chapter":"4 Measures of central tendency -II","heading":"4.3 Harmonic mean","text":"Harmonic means often used averaging things like rates (e.g.¬†\naverage travel speed given duration several trips). Harmonic mean\n(HM) set observations defined reciprocal \narithmetic average reciprocal given value.\\(x_{1},\\ x_{2},\\ldots,\\ x_{n}\\ \\)n observations \\[\\mathbf{\\text{H.M}} = \\frac{n}{\\sum_{= 1}^{n}\\frac{1}{x_{}}}\\]case Frequency distribution\\[\\mathbf{\\text{H.M}} = \\frac{n}{\\sum_{= 1}^{k}{f_{}\\frac{1}{x_{}}}}\\]\\(x_{}\\) mid-value, \\(f_{}\\) frequency , k \nnumber classes","code":""},{"path":"measures-of-central-tendency--ii.html","id":"steps-in-calculating-harmonic-mean-h.m","chapter":"4 Measures of central tendency -II","heading":"4.3.1 Steps in calculating Harmonic Mean (H.M)","text":"Calculate reciprocal (1/value) every value.Calculate reciprocal (1/value) every value.Find average reciprocals (just add divide \nmany )Find average reciprocals (just add divide \nmany )reciprocal average (=1/average)reciprocal average (=1/average)Example 4.4: given data 5, 10, 17, 24, 30 calculate H.MSolution 4.4:n = 5\\[\\mathbf{\\text{H.M}} = \\frac{n}{\\sum_{= 1}^{n}\\frac{1}{x_{}}} = \\frac{5}{0.433824} = 11.525\\]Example 4.5: Number tomatoes per plant given . Calculate\nharmonic mean.Solution 4.5:n =18\\[\\mathbf{\\text{H.M}} = \\frac{n}{\\sum_{= 1}^{n}{f_{}\\frac{1}{x_{}}}} = \\frac{18}{0.821898} = 21.90\\]","code":""},{"path":"measures-of-central-tendency--ii.html","id":"merits-and-demerits-of-harmonic-mean","chapter":"4 Measures of central tendency -II","heading":"4.4 Merits and Demerits of Harmonic mean","text":"MeritsIt rigidly defined.rigidly defined.defined observations.defined observations.amenable algebraic treatment.amenable algebraic treatment.suitable average desired give greater\nweight smaller less weight larger ones.suitable average desired give greater\nweight smaller less weight larger ones.DemeritsIt easily understood.easily understood.difficult compute.difficult compute.summary figure may actual item \nseriesIt summary figure may actual item \nseriesIt gives greater importance small items therefore, useful\nsmall items given greater weightage.gives greater importance small items therefore, useful\nsmall items given greater weightage.rarely used grouped data.rarely used grouped data.","code":""},{"path":"measures-of-central-tendency--ii.html","id":"relation-between-am-gm-and-hm","chapter":"4 Measures of central tendency -II","heading":"4.5 Relation between AM, GM and HM","text":"stands Arithmetic Mean, GM stands Geometric Mean HM\nstands Harmonic Mean; \\[\\mathbf{\\text{}}\\mathbf{\\times}\\mathbf{\\text{HM}}\\mathbf{=}\\mathbf{\\text{GM}}^{\\mathbf{2}}\\]also\\[\\mathbf{\\geq GM \\geq HM}\\]","code":""},{"path":"measures-of-central-tendency--ii.html","id":"when-to-use-am-gm-and-hm","chapter":"4 Measures of central tendency -II","heading":"4.6 When to use AM, GM and HM?","text":"practical answer depends numbers \nmeasuring.measuring units add linearly sequence; \nlengths, distances, weights, arithmetic mean give \nmeaningful average. example, arithmetic mean height \nweight students class represents average height weight \nstudents class.Harmonic mean give meaningful average, measuring\nunits add reciprocals sequence; speed \ndistance travelled per unit time, capacitance series, resistance \nparallel. example, harmonic mean capacitors series\nrepresents capacitance single capacitor \none capacitor used instead set capacitors series.‚Äôre measuring units multiply sequence; growth\nrates percentages, geometric mean give meaningful\naverage. example, geometric mean sequence different\nannual interest rates 10 years represents interest rate , \napplied constantly ten years, produce amount growth\nprincipal sequence different annual interest rates ten\nyears .","code":""},{"path":"measures-of-central-tendency--ii.html","id":"positional-averages","chapter":"4 Measures of central tendency -II","heading":"4.7 Positional Averages","text":"Positional average series values refers averages \ntaken series represents whole series\nmay positional properties.median, middle value series taken \nrepresentative value. Therefore, median positional average. Mode \nalso positional average modal values frequently\noccurring values directly taken series . \npositional averages include Percentiles, Quartiles \nDecilesNote Arithmetic mean, Harmonic mean Geometric mean termed\nmathematical averages","code":""},{"path":"measures-of-central-tendency--ii.html","id":"quartile","chapter":"4 Measures of central tendency -II","heading":"4.8 Quartiles","text":"median divides set data two equal parts. can also\ndivide set data two parts. ordered set \ndata divided four equal parts, division points called\nquartiles.first lower quartile (\\(\\mathbf{Q}_{\\mathbf{1}}\\)) \nvalue one fourth, 25% observations value.second quartile (\\(\\mathbf{Q}_{\\mathbf{2}}\\)), one-half,\n50% observations value. second quartile equal\nmedian.third upper quartile, (\\(\\mathbf{Q}_{\\mathbf{3}}\\)), \nvalue three-fourths, 75% observations .\\(\\mathbf{Q}_{\\mathbf{1}}\\mathbf{=}\\left( \\frac{\\mathbf{n + 1}}{\\mathbf{4}} \\right)^{\\mathbf{\\text{th}}}\\)item\\(\\mathbf{Q}_{\\mathbf{3}}\\mathbf{=}\\left( \\frac{\\mathbf{3(n + 1)}}{\\mathbf{4}} \\right)^{\\mathbf{\\text{th}}}\\)itemCalculations quartiles explained using example . See \nexample procedure followed fraction appear \ncalculation.Example 4.6: Compute quartiles data 25, 18, 30, 8, 15, 5,\n10, 35, 40, 45Solution 4.6:First arrange data ascending order5, 8, 10, 15, 18, 25, 30, 35, 40, 45here n = 10\\(\\mathbf{Q}_{\\mathbf{1}}\\mathbf{=}\\left( \\frac{\\mathbf{n + 1}}{\\mathbf{4}} \\right)^{\\mathbf{\\text{th}}}\\)itemi.e. \\(Q_{1} = \\left( \\frac{10 + 1}{4} \\right)^{th}\\) = 2.75th item;\nfraction appears use following procedure\\(Q_{1} = \\ \\)2.75th item = 2nd item + 0.75(3rd\nitem ‚Äì 2nd item)given data \\(Q_{1}\\)= 8+0.75(10‚Äì 8) = 9.5\\[\\mathbf{Q}_{\\mathbf{2}}\\mathbf{= median}\\]\\(Q_{2} = \\ \\)(18+25)/2 = 21.5\\(\\mathbf{Q}_{\\mathbf{3}}\\mathbf{=}\\left( \\frac{\\mathbf{3(n + 1)}}{\\mathbf{4}} \\right)^{\\mathbf{\\text{th}}}\\)itemi.e. \\(Q_{3} = \\left( 3 \\times \\frac{(10 + 1)}{4} \\right)^{th}\\) =\n8.25th item = 8th item + 0.25(9th item ‚Äì8th item) =\n35+0.25(40-35) =36.25","code":""},{"path":"measures-of-central-tendency--ii.html","id":"quartiles-of-a-discrete-frequency-data","chapter":"4 Measures of central tendency -II","heading":"4.8.1 Quartiles of a discrete frequency data","text":"Find cumulative frequencies.Find cumulative frequencies.Find \\(\\left( \\frac{\\mathbf{n + 1}}{\\mathbf{4}} \\right)\\)Find \\(\\left( \\frac{\\mathbf{n + 1}}{\\mathbf{4}} \\right)\\)See cumulative frequencies, value just greater \n\\(\\left( \\frac{\\mathbf{n + 1}}{\\mathbf{4}} \\right)\\) , \ncorresponding value \\(x\\) \\(Q_{1}\\)See cumulative frequencies, value just greater \n\\(\\left( \\frac{\\mathbf{n + 1}}{\\mathbf{4}} \\right)\\) , \ncorresponding value \\(x\\) \\(Q_{1}\\)Find \\(\\left( \\frac{\\mathbf{3(n + 1)}}{\\mathbf{4}} \\right)\\)Find \\(\\left( \\frac{\\mathbf{3(n + 1)}}{\\mathbf{4}} \\right)\\)See cumulative frequencies, value just greater \n\\(\\left( \\frac{\\mathbf{3(n + 1)}}{\\mathbf{4}} \\right)\\) ,\ncorresponding value \\(x\\) \\(Q_{3}\\)See cumulative frequencies, value just greater \n\\(\\left( \\frac{\\mathbf{3(n + 1)}}{\\mathbf{4}} \\right)\\) ,\ncorresponding value \\(x\\) \\(Q_{3}\\)Example 4.7: Compute quartiles data given bellowSolution 4.7:n =24\\(\\left( \\frac{\\mathbf{n + 1}}{\\mathbf{4}} \\right)\\) =\n\\(\\left( \\frac{\\mathbf{n + 1}}{\\mathbf{4}} \\right)\\mathbf{\\ }\\)=\n\\(\\left( \\frac{\\mathbf{25}}{\\mathbf{4}} \\right)\\)= 6.25The cumulative frequency value just greater 6.25 7, \\(\\mathbf{x}\\) value corresponding cumulative frequency 7 8. \n\\(\\mathbf{Q}_{\\mathbf{1}}\\)= 8.\\(\\left( \\frac{\\mathbf{3(n + 1)}}{\\mathbf{4}} \\right)\\) =\n\\(\\left( \\frac{\\mathbf{3}\\mathbf{\\times}\\mathbf{25}}{\\mathbf{4}} \\right)\\)=\n18.75The cumulative frequency value just greater 18.75 20, \\(\\mathbf{x}\\) value corresponding cumulative frequency 20 24. \n\\(\\mathbf{Q}_{\\mathbf{3}}\\)= 24.","code":""},{"path":"measures-of-central-tendency--ii.html","id":"quartiles-of-a-continuous-frequency-data","chapter":"4 Measures of central tendency -II","heading":"4.8.2 Quartiles of a continuous frequency data","text":"Find cumulative frequenciesFind cumulative frequenciesFind \\(\\left( \\frac{\\mathbf{n}}{\\mathbf{4}} \\right)\\)Find \\(\\left( \\frac{\\mathbf{n}}{\\mathbf{4}} \\right)\\)See cumulative frequencies, value just greater\n\\(\\ \\left( \\frac{\\mathbf{n}}{\\mathbf{4}} \\right)\\), \ncorresponding class interval called first quartile class.See cumulative frequencies, value just greater\n\\(\\ \\left( \\frac{\\mathbf{n}}{\\mathbf{4}} \\right)\\), \ncorresponding class interval called first quartile class.Find \\(3\\left( \\frac{\\mathbf{n}}{\\mathbf{4}} \\right)\\)Find \\(3\\left( \\frac{\\mathbf{n}}{\\mathbf{4}} \\right)\\)See cumulative frequencies value just greater \n\\(3\\left( \\frac{\\mathbf{n}}{\\mathbf{4}} \\right)\\mathbf{\\ }\\)\ncorresponding class interval called 3rd quartile class.\napply respective formulaeSee cumulative frequencies value just greater \n\\(3\\left( \\frac{\\mathbf{n}}{\\mathbf{4}} \\right)\\mathbf{\\ }\\)\ncorresponding class interval called 3rd quartile class.\napply respective formulae\\[\\mathbf{Q}_{\\mathbf{1}}\\mathbf{=}\\mathbf{l}_{\\mathbf{1}}\\mathbf{+}\\frac{\\frac{\\mathbf{n}}{\\mathbf{4}}\\mathbf{-}\\mathbf{m}_{\\mathbf{1}}}{\\mathbf{f}_{\\mathbf{1}}}\\mathbf{\\times}\\mathbf{c}_{\\mathbf{1}}\\]\\[\\mathbf{Q}_{\\mathbf{3}}\\mathbf{=}\\mathbf{l}_{\\mathbf{3}}\\mathbf{+}\\frac{\\mathbf{3}\\left( \\frac{\\mathbf{n}}{\\mathbf{4}} \\right)\\mathbf{-}\\mathbf{m}_{\\mathbf{3}}}{\\mathbf{f}_{\\mathbf{3}}}\\mathbf{\\times}\\mathbf{c}_{\\mathbf{3}}\\]\\(l_{1}\\) = lower limit first quartile class\\(f_{1}\\) = frequency first quartile class\\(c_{1}\\) = width first quartile class\\(m_{1}\\) = cumulative frequency preceding first quartile class\\(l_{3}\\)= 1ower limit 3rd quartile class\\(f_{3}\\)= frequency 3rd quartile class\\(c_{3}\\)= width 3rd quartile class\\(m_{3}\\) = cumulative frequency preceding 3rd quartile classExample 4.8: Find quartiles grouped frequency data givenSolution 4.8:\\(\\left( \\frac{n}{4} \\right)\\) = \\(\\frac{204}{4}\\) = 51The cumulative frequency value just greater 51 54 class\n20-30 1st quartile class\\[\\mathbf{Q}_{\\mathbf{1}}\\mathbf{=}\\mathbf{l}_{\\mathbf{1}}\\mathbf{+}\\frac{\\frac{\\mathbf{n}}{\\mathbf{4}}\\mathbf{-}\\mathbf{m}_{\\mathbf{1}}}{\\mathbf{f}_{\\mathbf{1}}}\\mathbf{\\times}\\mathbf{c}_{\\mathbf{1}}\\]\\[\\mathbf{= 20 +}\\frac{\\mathbf{51 - 29}}{\\mathbf{25}}\\mathbf{\\times 10\\  = 28.8}\\]\\(3\\left( \\frac{n}{4} \\right)\\) = \\(3 \\times \\frac{204}{4}\\) = 153The cumulative frequency value just greater 153 167 class\n60-70 3rd quartile class\\[\\mathbf{Q}_{\\mathbf{3}}\\mathbf{=}\\mathbf{l}_{\\mathbf{3}}\\mathbf{+}\\frac{\\mathbf{3}\\left( \\frac{\\mathbf{n}}{\\mathbf{4}} \\right)\\mathbf{-}\\mathbf{m}_{\\mathbf{3}}}{\\mathbf{f}_{\\mathbf{3}}}\\mathbf{\\times}\\mathbf{c}_{\\mathbf{3}}\\]\\[\\mathbf{= 60 +}\\frac{\\mathbf{153 - 145}}{\\mathbf{22}}\\mathbf{\\times 10 = 63.63}\\]","code":""},{"path":"measures-of-central-tendency--ii.html","id":"percentiles","chapter":"4 Measures of central tendency -II","heading":"4.9 Percentiles","text":"percentile values divide ordered set data 100 equal parts\ncontaining 1 percent observations. xth percentile,\ndenoted \\(P_{x}\\) value x percent values \ndistribution fall. may noted median 50th\npercentile, 25th percentile first quartile \\(Q_{1}\\) 75th\npercentile \\(\\text{\\ Q}_{3}\\ \\)raw data, first arrange n observations increasing order.\nxth percentile given \\(\\mathbf{P}_{\\mathbf{x}}\\mathbf{=}\\left( \\frac{\\mathbf{x}\\left( \\mathbf{n + 1} \\right)}{\\mathbf{100}} \\right)^{\\mathbf{\\text{th}}}\\)itemFor frequency distribution xth percentile given \nfollowing stepsFind cumulative frequenciesFind cumulative frequenciesFind \\(\\left( \\frac{\\text{x.n}}{100} \\right)\\)Find \\(\\left( \\frac{\\text{x.n}}{100} \\right)\\)See cumulative frequencies, value just greater\n\\(\\left( \\frac{\\text{x.n}}{100} \\right)\\)\ncorresponding class interval called Percentile class.See cumulative frequencies, value just greater\n\\(\\left( \\frac{\\text{x.n}}{100} \\right)\\)\ncorresponding class interval called Percentile class.Use following formulaUse following formula\\[\\mathbf{P}_{\\mathbf{x}}\\mathbf{= l +}\\frac{\\left( \\frac{\\mathbf{x \\times n}}{\\mathbf{100}} \\right)\\mathbf{- cf}}{\\mathbf{f}}\\mathbf{\\times c}\\]\\(\\mathbf{l}\\) = lower limit percentile class\\(\\mathbf{\\text{cf}}\\) = cumulative frequency preceding percentile\nclass\\(\\mathbf{f}\\) = frequency percentile class\\(\\mathbf{c}\\) = class interval\\(\\mathbf{n}\\) = total number observationsExample 4.9: Compute \\(\\mathbf{P}_{\\mathbf{25}}\\)\n\\(\\mathbf{P}_{\\mathbf{75}}\\) data 25, 18, 30, 8, 15, 5, 10, 35,\n40, 45Solution 4.9:First arrange data ascending order5, 8, 10, 15, 18, 25, 30, 35, 40, 45Here n =10\\(\\mathbf{P}_{\\mathbf{25}}\\mathbf{=}\\left( \\frac{\\mathbf{25}\\left( \\mathbf{10 + 1} \\right)}{\\mathbf{100}} \\right)^{\\mathbf{\\text{th}}}\\)=\n2.75th item\\(P_{25} = \\ \\)2.75th item = 2nd item + 0.75(3rd\nitem ‚Äì 2nd item)given data \\(P_{25}\\)= 8+0.75(10‚Äì 8) = 9.5\\(\\mathbf{P}_{\\mathbf{75}}\\mathbf{=}\\left( \\frac{\\mathbf{75}\\left( \\mathbf{10 + 1} \\right)}{\\mathbf{100}} \\right)^{\\mathbf{\\text{th}}}\\)=\n8.25th itemi.e. \\(P_{75} = \\left( 75 \\times \\frac{10 + 1}{100} \\right)^{th}\\) =\n8.25th item = 8th item + 0.25(9th item ‚Äì8th item) =\n35+0.25(40-35) =36.25Note: Data example Example 3.6; can seen\n\\(P_{25} = Q_{1}\\) & \\(P_{75} = Q_{3}\\) always","code":""},{"path":"measures-of-central-tendency--ii.html","id":"deciles","chapter":"4 Measures of central tendency -II","heading":"4.10 Deciles","text":"Deciles similar quartiles. quartiles three points\ndivide ordered set data four quarters, deciles 9\npoints divide ordered set data ten equal parts. \nxth decile denoted \\(\\text{\\ d}_{x}\\). may noted \nmedian 5thdecile.\\(\\mathbf{d}_{\\mathbf{x}}\\mathbf{=}\\left( \\frac{\\mathbf{x}\\left( \\mathbf{n + 1} \\right)}{\\mathbf{10}} \\right)^{\\mathbf{\\text{th}}}\\)itemFor frequency distribution xth decile given following\nstepsFind cumulative frequenciesFind cumulative frequenciesFind \\(\\left( \\frac{\\text{x.n}}{10} \\right)\\)Find \\(\\left( \\frac{\\text{x.n}}{10} \\right)\\)See cumulative frequencies, value just greater\n\\(\\left( \\frac{\\text{x.n}}{10} \\right)\\)corresponding\nclass interval called decile class.See cumulative frequencies, value just greater\n\\(\\left( \\frac{\\text{x.n}}{10} \\right)\\)corresponding\nclass interval called decile class.Use following formulaUse following formula\\[\\mathbf{d}_{\\mathbf{x}}\\mathbf{= l +}\\frac{\\left( \\frac{\\mathbf{x \\times n}}{\\mathbf{10}} \\right)\\mathbf{- cf}}{\\mathbf{f}}\\mathbf{\\times c}\\]\\(\\mathbf{l}\\) = lower limit decile class\\(\\mathbf{\\text{cf}}\\) = cumulative frequency preceding decile class\\(\\mathbf{f}\\) = frequency decile class\\(\\mathbf{c}\\) = class interval\\(\\mathbf{n}\\) = total number observationsThe best thing statistician get play everybody else‚Äôs backyard.\n‚Äì John Tukey","code":""},{"path":"measures-of-dispersion.html","id":"measures-of-dispersion","chapter":"5 Measures of Dispersion","heading":"5 Measures of Dispersion","text":"discussed previous lectures, set data can summarized\nsingle representative value describes central value \ndata. Consider two sets data & B belowYou can see mean, median mode sets & B 3See dot diagrams data sets B.\nFigure 5.1: Scatter diagram data sets & B\ncan seen , values data set grouped close \nmean, values data set B spread . \nsay values data set B dispersed (scattered) \ndata set AThis example shows mean, mode median, \nenough describing set data. addition using measures,\nneed numerical measure dispersion (variation) set \ndata.Statistical dispersion means extent numerical data \nlikely vary average value.","code":""},{"path":"measures-of-dispersion.html","id":"characteristics-of-a-good-measure-of-dispersion","chapter":"5 Measures of Dispersion","heading":"5.1 Characteristics of a good measure of dispersion","text":"ideal measure dispersion expected possess following\npropertiesIt rigidly definedIt rigidly definedIt based items.based items.unduly affected extreme items.unduly affected extreme items.lend algebraic manipulation.lend algebraic manipulation.simple understand easy calculateIt simple understand easy calculateThe important measures dispersion Range, \nInter-quartile range, Mean Absolute Deviation (MAD)standard deviation.","code":""},{"path":"measures-of-dispersion.html","id":"the-range","chapter":"5 Measures of Dispersion","heading":"5.2 The Range","text":"simplest possible measure dispersion. range set\ndata defined difference largest observation \nsmallest observation set data.Thus,Range = largest observation ‚Äì smallest observation.symbols, Range = L ‚Äì S.L = Largest value; S = Smallest value.individual observations discrete series, L S easily\nidentified. continuous series, following two methods \nfollowed.","code":""},{"path":"measures-of-dispersion.html","id":"method-1","chapter":"5 Measures of Dispersion","heading":"5.2.1 Method 1","text":"L = Upper boundary highest classS = Lower boundary lowest class.","code":""},{"path":"measures-of-dispersion.html","id":"method-2","chapter":"5 Measures of Dispersion","heading":"5.2.2 Method 2","text":"L = Mid-value highest class.S = Mid-value lowest class.Example 5.1: marks obtained 8 students Mathematics \nPhysics examinations follows:Mathematics: 35, 60, 70, 40, 85, 96, 55, 65.Physics: 50, 55, 70, 65, 89, 68, 72, 80.Find ranges two sets data. Physics marks \ndispersed Mathematics marks?SolutionFor Mathematics,Highest mark = 96, lowest mark = 35, range =96 ‚Äì 35 = 61For Physics,Highest mark = 89, lowest mark = 50, range =89 ‚Äì 50 = 39.mathematics marks wider range Physics marks. \nMathematics marks therefore dispersed Physics marks.Example 5.2: Calculate range following distributionSolutionL = Upper boundary highest class = 75S = Lower boundary lowest class = 60Range = L ‚Äì S = 75 ‚Äì 60 = 15","code":""},{"path":"measures-of-dispersion.html","id":"merits-and-demerits-of-range","chapter":"5 Measures of Dispersion","heading":"5.2.3 Merits and Demerits of Range","text":"MeritsIt simple understand.simple understand.easy calculate.easy calculate.certain types problems like quality control, weather\nforecasts, share price analysis, etc.certain types problems like quality control, weather\nforecasts, share price analysis, etc.DemeritsIt much affected extreme items.much affected extreme items.based two extreme observations.based two extreme observations.calculated open-end class intervals.calculated open-end class intervals.suitable mathematical treatment.suitable mathematical treatment.rarely used measure.rarely used measure.","code":""},{"path":"measures-of-dispersion.html","id":"the-inter-quartile-range-iqr-or-midspread","chapter":"5 Measures of Dispersion","heading":"5.3 The Inter-Quartile Range (IQR) or Midspread","text":"range advantage quick easy calculate.\nHowever, since depends maximum minimum values \nset data, show whole data distributed\ntwo values. range therefore good measure \ndispersion one two values differ greatly \nvalues data. overcome problem, sometimes use \ninter-quartile range. robust measure dispersion \ninter-quartile range. inter-quartile range set data \ndifference upper lower quartiles data. Thus,Inter-Quartile Range (IQR) = Q3 ‚Äì Q1.inter-quartile range set data therefore affected \nvalues data outside Q1 Q3. inter-quartile range\nsometimes used measure dispersion.Example 5.3: Consider two sets data , find IQRA: 3, 4, 5, 6, 8, 9, 10, 12, 15B: 3, 8, 8, 9, 9, 9, 10, 10, 15For data set , Q1 = 5, Q3 = 10; Inter-Quartile Range =10 ‚Äì\n5 = 5For data set B, Q1 = 8, Q3 = 10; Inter-Quartile Range =10 ‚Äì\n8 = 2Since inter-quartile range data set greater \ndata set B, results confirm data set dispersed \ndata set B. can also see Range sets.","code":""},{"path":"measures-of-dispersion.html","id":"mean-absolute-deviation-mad","chapter":"5 Measures of Dispersion","heading":"5.4 Mean Absolute Deviation (MAD)","text":"mean absolute deviation (MAD) measure variability \nindicates average distance observations mean. MAD\nuses original units data, simplifies interpretation.\nLarger values signify data points spread \naverage. Conversely, lower values correspond data points bunching\ncloser . mean absolute deviation also known mean\ndeviation average absolute deviation.calculate mean absolute deviation.Calculate mean.Calculate mean.Calculate difference observation mean take\nabsolute value .e. ignore sign. difference known \nabsolute deviationCalculate difference observation mean take\nabsolute value .e. ignore sign. difference known \nabsolute deviationAdd deviations together.Add deviations together.Divide sum number data points.Divide sum number data points.\\[MAD = \\frac{\\sum_{= 1}^{n}\\left| x_{} - \\overline{x} \\right|}{n}\\]Example 5.4: find mean absolute deviation following 10, 15,\n15, 17, 18, 21Here n = 6 \\(\\sum_{= 1}^{n}\\left| x_{} - \\overline{x} \\right|\\) =\n16 therefore MAD = \\(\\frac{16}{6} = 2.67\\)","code":""},{"path":"measures-of-dispersion.html","id":"merits-and-demerits-of-mad","chapter":"5 Measures of Dispersion","heading":"5.4.1 Merits and Demerits of MAD","text":"MeritsSimple EasySimple EasyDifferent items observations can easily compared mean deviationDifferent items observations can easily compared mean deviationMean deviation better quartile deviation range based observations series.Mean deviation better quartile deviation range based observations series.Mean deviation less affected extreme values series comparing standard deviation.Mean deviation less affected extreme values series comparing standard deviation.Mean deviation rigidly defined. , fixed value.Mean deviation rigidly defined. , fixed value.DemeritsIt becomes difficult compute mean deviation case fractions.becomes difficult compute mean deviation case fractions.Mean deviation applicable algebraic calculations.Mean deviation applicable algebraic calculations.calculated open-end class intervals.calculated open-end class intervals.Mean deviation good measure ignores negative signs deviations.Mean deviation good measure ignores negative signs deviations.","code":""},{"path":"measures-of-dispersion.html","id":"the-variance-and-standard-deviation","chapter":"5 Measures of Dispersion","heading":"5.5 The variance and standard deviation","text":"important measures variability sample variance \nsample standard deviation. x1, x2‚Ä¶ xn sample\nn observations, sample variance denoted s¬≤ \ndefined equation.\\[{\\mathbf{\\text{sample variance}},\\ \\mathbf{s}}^{\\mathbf{2}}\\mathbf{=}\\frac{\\sum_{\\mathbf{= 1}}^{\\mathbf{n}}\\left( \\mathbf{x}_{\\mathbf{}}\\mathbf{-}\\overline{\\mathbf{x}} \\right)^{\\mathbf{2}}}{\\mathbf{n - 1}}\\]sample standard deviation, s, positive square root \nsample variance.\\[\\mathbf{variance =}\\left( \\mathbf{\\text{standard deviation}} \\right)^{\\mathbf{2}}\\]\\[\\mathbf{standard\\ deviation = \\ }\\sqrt{\\mathbf{\\text{variance}}}\\]Note: sA, standard deviation data set , greater\nsB, standard deviation data set B, data set \ndispersed data set B. noted standard\ndeviation set data non-negative number.Example 5.4: Consider two sets data & B ; find standard\ndeviation?Solution:Mean (\\(\\overline{x}\\)) =\\(\\ \\frac{18}{6} = 3\\)\\[{Sample\\ variane,\\ s}_{}^{2} = \\frac{\\sum_{= 1}^{n}\\left( x_{} - \\overline{x} \\right)^{2}}{n - 1} = \\frac{10}{5} = 2\\]\\[\\text{sample standard deviation,}\\ s_{} = \\ \\sqrt{s_{}^{2}} = \\ \\sqrt{2} = 1.414\\]Mean (\\(\\overline{x}\\)) =\\(\\ \\frac{18}{6} = 3\\)\\[{Sample\\ variane,\\ s}_{B}^{2} = \\frac{\\sum_{= 1}^{n}\\left( x_{} - \\overline{x} \\right)^{2}}{n - 1} = \\frac{54}{5} = 10.8\\]\\[sample\\ standard\\ deviation,\\ s_{B} = \\ \\sqrt{s_{B}^{2}} = \\ \\sqrt{10.8} = 3.29\\]can seen \\(s_{B} > s_{}\\ \\), confirming data set B \ndispersed data set (see dot diagrams)Note: unit measurement sample variance square\nunit measurement data. Sample standard deviation \nunit measurement data. Thus, x measured \ncentimetres (cm), unit measurement sample variance \ncm2 sample standard deviation cm. standard\ndeviation desirable property measuring variability \nunit data.alternative formula computing varianceThe computation s¬≤ requires calculations \\(\\overline{x}\\), n\nsubtractions n squaring adding operations. original\nobservations deviations \\(\\left( x_{} - \\overline{x} \\right)\\) \nintegers, deviations \\(\\left( x_{} - \\overline{x} \\right)\\) may\ndifficult work , several decimals may carried\nensure numerical accuracy. efficient computational formula \ns¬≤ given \\(s^{2} = \\frac{1}{n - 1}\\left\\{ \\sum_{= 1}^{n}{x_{}^{2} - \\frac{1}{n}}\\left( \\sum_{= 1}^{n}x_{} \\right)^{2} \\right\\}\\)Example 5.5: Consider data set ; find standard deviation?Solution:\\(s^{2} = \\frac{1}{n - 1}\\left\\{ \\sum_{= 1}^{n}{x_{}^{2} - \\frac{1}{n}}\\left( \\sum_{= 1}^{n}x_{} \\right)^{2} \\right\\}\\)\n; n = 9\\(s^{2} = \\frac{1}{8}\\left\\{ 700 - {\\frac{1}{9}\\left( 72 \\right)}^{2} \\right\\}\\)\n=15.5\\(s = \\ \\sqrt{15.5} = 3.94\\)","code":""},{"path":"measures-of-dispersion.html","id":"variance-and-standard-deviation-for-grouped-data","chapter":"5 Measures of Dispersion","heading":"5.5.1 Variance and standard deviation for grouped data","text":"","code":""},{"path":"measures-of-dispersion.html","id":"for-discrete-grouped-data","chapter":"5 Measures of Dispersion","heading":"5.5.1.1 For discrete grouped data","text":"\\[s^{2} = \\frac{1}{n - 1}\\left\\{ \\sum_{= 1}^{n}{{f_{}x}_{}^{2} - \\frac{1}{n}}\\left( \\sum_{= 1}^{n}{f_{}x}_{} \\right)^{2} \\right\\}\\]\\(f_{}\\) frequency ith observationExample 5.6: frequency distributions seed yield 50 sesamum\nplants given . Find standard deviation.Solution:\\[s^{2} = \\frac{1}{n - 1}\\left\\{ \\sum_{= 1}^{n}{{f_{}x}_{}^{2} - \\frac{1}{n}}\\left( \\sum_{= 1}^{n}{f_{}x}_{} \\right)^{2} \\right\\}\\]\\[{sample\\ variance,\\ s}^{2} = \\frac{1}{50 - 1}\\left\\{ 1537 - \\frac{271^{2}}{50} \\right\\} = 1.3914\\]\\(standard\\ deviation,\\ s = \\sqrt{1.3914}\\) = 1.179","code":""},{"path":"measures-of-dispersion.html","id":"for-continuous-grouped-data","chapter":"5 Measures of Dispersion","heading":"5.5.1.2 For continuous grouped data","text":"\\[s^{2} = \\frac{1}{n - 1}\\left\\{ \\sum_{= 1}^{n}{{f_{}d}_{}^{2} - \\frac{1}{n}}\\left( \\sum_{= 1}^{n}{f_{}d}_{} \\right)^{2} \\right\\}\\]\\(f_{}\\) frequency ith class, c class\ninterval, \\(d_{} = \\frac{x_{} - }{c}\\), \\(x_{}\\) class mark, \\(\\)\nclass mark highest frequencyExample 5.7: frequency distributions seed yield 50 sesamum\nplants given . Find standard deviationSolution:n =50; c =1A = 5\\[s^{2} = \\frac{1}{n - 1}\\left\\{ \\sum_{= 1}^{n}{{f_{}d}_{}^{2} - \\frac{1}{n}}\\left( \\sum_{= 1}^{n}{f_{}d}_{} \\right)^{2} \\right\\}\\]\\[{sample\\ variance,\\ s}^{2} = \\frac{1}{49}\\left( 77 - \\frac{\\left( 21 \\right)^{2}}{50} \\right) = \\ 1.3914\\]\\(standard\\ deviation,\\ s = \\sqrt{1.3914}\\) = 1.179","code":""},{"path":"measures-of-dispersion.html","id":"merits-and-demerits-of-standard-deviation","chapter":"5 Measures of Dispersion","heading":"5.5.2 Merits and Demerits of Standard Deviation","text":"MeritsIt rigidly defined value always definite based \nobservationsIt rigidly defined value always definite based \nobservationsAs based arithmetic mean, merits \narithmetic mean.based arithmetic mean, merits \narithmetic mean.important widely used measure dispersion.important widely used measure dispersion.possible algebraic treatment.possible algebraic treatment.less affected fluctuations sampling hence\nstable.less affected fluctuations sampling hence\nstable.basis measuring coefficient correlation \nmeasures.basis measuring coefficient correlation \nmeasures.DemeritsIt easy understand difficult calculate.easy understand difficult calculate.gives weight extreme values values \nsquared .gives weight extreme values values \nsquared .absolute measure variability, used \npurpose comparison.absolute measure variability, used \npurpose comparison.","code":""},{"path":"measures-of-dispersion.html","id":"coefficient-of-variation-relative-measure-of-dispersion","chapter":"5 Measures of Dispersion","heading":"5.6 Coefficient of Variation (relative measure of dispersion)","text":"Standard deviation absolute measure dispersion. \nexpressed terms units original figures collected\nstated. standard deviation heights plants \ncompared standard deviation weights grains, \nexpressed different units, .e heights centimetre \nweights kilograms.Therefore standard deviation must converted relative\nmeasure dispersion purpose comparison. relative\nmeasure known coefficient variation. coefficient \nvariation obtained dividing standard deviation mean \nexpressed percentage.\\[\\mathbf{\\text{Coefficient variation}}\\left( \\mathbf{C}\\mathbf{.}\\mathbf{V} \\right)\\mathbf{=}\\frac{\\mathbf{\\text{standard deviation}}}{\\mathbf{\\text{mean}}}\\mathbf{\\times 100}\\]want compare variability two series, can use\nC.V. series groups data C.V. greater indicate\ngroup variable, less stable, less uniform, less\nconsistent less homogeneous. C.V. less, indicates \ngroup less variable stable uniform \nconsistent homogeneous.Example 5.8: Consider measurement yield plant height \npaddy variety. mean standard deviation yield 50 kg \n10 kg respectively. mean standard deviation plant height \n55 cm 5 cm respectively. Compare variability.Solution:measurements yield plant height different units.\nHence variability can compared using coefficient \nvariation.yield, CV=\\(\\ \\frac{10}{50} \\times 100 =\\) 20%plant height, CV=\n\\(\\frac{5}{55} \\times 100 = \\ \\)9.1%yield subject variation plant height.******************************************************************","code":""},{"path":"skewness-and-kurtosis.html","id":"skewness-and-kurtosis","chapter":"6 Skewness and Kurtosis","heading":"6 Skewness and Kurtosis","text":"previous lectures learned numerical measures central\ntendency dispersion, measures shape?histogram can give general idea shape \ndistribution values data. need numerical measures\nidentify shape distribution. numerical measures \ndeal shape distribution Skewness Kurtosis.","code":""},{"path":"skewness-and-kurtosis.html","id":"skewness","chapter":"6 Skewness and Kurtosis","heading":"6.1 Skewness","text":"Skewness measure symmetry, precisely, lack \nsymmetry. may ask, symmetric distribution looks\nlike. Histogram symmetric distribution showed :\nFigure 6.1: Histogram symmetric distribution\ndistribution, data set, symmetric looks \nleft right centre point. discussion including\nunimodal cases.symmetric distribution skewness = 0; mean = median = mode\nFigure 6.2: symmetric distribution\nExample data set skewness = 0 (symmetric distribution)\nFigure 6.3: Data set skewness = 0\n","code":""},{"path":"skewness-and-kurtosis.html","id":"left-skewed-or-negatively-skewed","chapter":"6 Skewness and Kurtosis","heading":"6.1.1 Left-skewed or negatively skewed","text":"negatively skewed data set distribution, left tail longer;\nmass distribution concentrated right figure.\ndistribution said left-skewed, left-tailed, skewed \nleft, considering long tail left side. See\nfigure , can also see Mean < Median < Mode.\nFigure 6.4: Left skewed negatively skewed distribution\nExample data set negative skewness\nFigure 6.5: Negatively skewed data set\n","code":""},{"path":"skewness-and-kurtosis.html","id":"right-skewed-or-positively-skewed","chapter":"6 Skewness and Kurtosis","heading":"6.1.2 Right-skewed or positively skewed","text":"positively skewed data set distribution, right tail \nlonger; mass distribution concentrated left \nfigure. distribution said right-skewed, right-tailed, \nskewed right, considering long tail right\nside. See figure , can also see Mean > Median > Mode\nFigure 6.6: Right skewed positively skewed distribution\nExample data set positive skewness\nFigure 6.7: Data set positive skewness (right skewed)\n","code":""},{"path":"skewness-and-kurtosis.html","id":"measures-of-skewness","chapter":"6 Skewness and Kurtosis","heading":"6.2 Measures of Skewness","text":"direction extent skewness can measured various ways. \nshall discuss four measures.","code":""},{"path":"skewness-and-kurtosis.html","id":"karl-pearsons-coefficient-of-skewness-s_k","chapter":"6 Skewness and Kurtosis","heading":"6.2.1 Karl Pearson‚Äôs coefficient of Skewness (\\(S_{k}\\))","text":"noticed mean, median mode equal \nskewed distribution. Karl Pearson's measure skewness based\nupon divergence mean mode skewed distribution.\\[S_{k} = \\frac{mean - mode}{\\text{standard deviation}}\\]sign \\(S_{k}\\) gives direction skewness magnitude\ngives extent skewness. \\(S_{k}\\) > 0, distribution \npositively skewed, \\(S_{k}\\) < 0 negatively skewed.formula since mode used, problem mode\ndefined distribution find \\(S_{k}\\). empirical\nrelation mean, median mode states , moderately\nsymmetrical distribution\\(\\ mean - mode \\approx 3(mean - median)\\). \nformula can written \\[S_{k} = \\frac{3(mean - median)}{\\text{standard deviation}}\\]Example 6.1: Compute Karl Pearson's coefficient skewness \nfollowing data:Solution:Mean,\n\\(\\overline{x} = \\frac{\\sum_{= 1}^{n}{f_{}x_{}}}{\\sum_{= 1}^{n}f_{}}\\)\n= \\(\\frac{11482}{187} = 61.40\\)\\({sample\\ variance,\\ s}^{2} = \\frac{1}{n - 1}\\left\\{ \\sum_{= 1}^{n}{{f_{}x}_{}^{2} - \\frac{1}{n}}\\left( \\sum_{= 1}^{n}{f_{}x}_{} \\right)^{2} \\right\\}\\)=\n\\(\\frac{705588 - \\frac{\\left( 11482 \\right)^{2}}{187}}{186} = 3.123\\)\\(standard\\ deviation,\\ s = \\sqrt{3.123} = 1.179\\)Median: See cumulative frequencies, value just greater\n\\(\\ \\left( \\frac{n + 1}{2} \\right)\\) , corresponding value \n\\(x\\) \\(Q_{2}\\), median\\(\\left( \\frac{n + 1}{2} \\right) = \\frac{187 + 1}{2}\\ \\)= \\(\\frac{188}{2}\\)\n= 94\\[S_{k} = \\frac{3(mean - median)}{\\text{standard deviation}}\\]\\[S_{k} = \\frac{3(61.40 - 61)}{1.179} = \\frac{1.2}{1.179} = 1.017\\]Hence, Karl Pearson's coefficient skewness \\(S_{k}\\)=\\(1.017\\), Thus\ndistribution positively skewed.","code":""},{"path":"skewness-and-kurtosis.html","id":"bowleys-measure-of-skewness-sq","chapter":"6 Skewness and Kurtosis","heading":"6.2.2 Bowley's measure of Skewness (SQ)","text":"Karl Pearson's coefficient skewness commonly used skewness\nmeasure. However, order use must know mean, mode (\nmedian) standard deviation data. Sometimes might \ninformation; instead might information \nquartiles. ‚Äôs case, can use Bowley‚Äôs measure Skewness\nalternative find asymmetry \ndistribution. ‚Äôs useful extreme data values\n(outliers) open-ended distribution.\\[{Bowley‚Äôs\\ measure\\ \\ Skewness,\\ S}_{Q} = \\frac{\\left( Q_{3} - Q_{2} \\right) - \\left( Q_{2} - Q_{1} \\right)}{\\left( Q_{3} - Q_{2} \\right) + \\left( Q_{2} - Q_{1} \\right)}\\]\\(Q_{1}\\)= 1st quartile; \\(Q_{2}\\) = median; \\(Q_{3}\\)= 3rd quartileEquation can modified \\[S_{Q} = \\frac{Q_{3} - 2Q_{2} + Q_{1}}{Q_{3} - Q_{1}}\\]\\(S_{Q}\\)= 0 means curve symmetrical.\\(S_{Q}\\)= 0 means curve symmetrical.\\(S_{Q}\\) > 0 means curve positively skewed.\\(S_{Q}\\) > 0 means curve positively skewed.\\(S_{Q}\\)< 0 means curve negatively skewed.\\(S_{Q}\\)< 0 means curve negatively skewed.Example 6.1 given , Bowley's measure Skewness can \ncalculated followsCalculation \\(\\text{Q}_{1}\\), \\(Q_{2}\\), \\(Q_{3}\\) given Section 4.8\\[{Q}_{1} = 60\\]\\[Q_{2} = 61\\]\\[Q_{3} = 63\\]\\[S_{Q} = \\frac{63 - (2 \\times 61) + 60}{63 - 60} = \\ \\frac{1}{3} = 0.33\\]Since \\(S_{Q}\\) > 0 means curve positively skewed.","code":""},{"path":"skewness-and-kurtosis.html","id":"kellys-measure-of-skewness-sp","chapter":"6 Skewness and Kurtosis","heading":"6.2.3 Kelly's Measure of Skewness (Sp)","text":"Bowley's measure skewness based middle 50% \nobservations; leaves 25% observations extreme \ndistribution. improvement Bowley's measure, Kelly \nsuggested measure based Percentiles, including P10 P90\n10% observations extreme ignored.\\[{Kelly's\\ Measure\\ \\ Skewness,\\ S}_{p} = \\frac{\\left( P_{90} - P_{50} \\right) - \\left( P_{50} - P_{10} \\right)}{\\left( P_{90} - P_{50} \\right) + \\left( P_{50} - P_{10} \\right)}\\]","code":""},{"path":"skewness-and-kurtosis.html","id":"measure-based-on-moments","chapter":"6 Skewness and Kurtosis","heading":"6.2.4 Measure based on moments","text":"going measuring skewness using moments, one know \nmoment :","code":""},{"path":"skewness-and-kurtosis.html","id":"moments","chapter":"6 Skewness and Kurtosis","heading":"6.2.4.1 Moments","text":"rth moment mean distribution, denoted \nŒºr given \\[\\mu_{r} = \\frac{\\sum_{= 1}^{N}{f_{}\\left( x_{} - \\overline{x} \\right)^{r}}}{N}\\]\\(f_{}\\) frequency ith observation class\nmark\\(\\ x_{}\\), \\(N = \\sum_{}^{}f_{}\\), number observationsMoment mean also called Central MomentIf r = 0,\n\\(\\mu_{0} = \\frac{\\sum_{= 1}^{N}{f_{}\\left( x_{} - \\overline{x} \\right)^{0}}}{N}\\)\n= 1If r = 1,\n\\(\\mu_{1} = \\frac{\\sum_{= 1}^{N}{f_{}\\left( x_{} - \\overline{x} \\right)^{1}}}{N}\\)\n= 0 (sum deviation mean zero)r = 2,\n\\(\\mu_{2} = \\frac{\\sum_{= 1}^{N}{f_{}\\left( x_{} - \\overline{x} \\right)^{2}}}{N}\\)\n= \\(\\sigma^{2}\\), Population varianceIn short values following moments mean areMoments meanFor Example 6.1 given , calculate third central moment, \\(\\mu_{3}\\)Mean = 61.40\\[\\mu_{3} = \\frac{\\sum_{= 1}^{N}{f_{}\\left( x_{} - \\overline{x} \\right)^{3}}}{N} = \\ \\frac{49.832}{187} = 0.266\\]","code":""},{"path":"skewness-and-kurtosis.html","id":"moment-measure-of-skewness-mathbfbeta_1textandgamma_1mathbf","chapter":"6 Skewness and Kurtosis","heading":"6.2.4.2 Moment Measure of Skewness \\(\\mathbf{(}\\beta_{1}\\text{and}\\)\\(\\gamma_{1}\\mathbf{)}\\)","text":"moment measure skewness based property , \nsymmetrical distribution, odd ordered central moments equal \nzero. note \\(\\mu_{1}\\) = 0, every distribution, therefore, \nlowest order moment can provide absolute measure skewness\n\\(\\text{Œº}_{3}\\). measures skewness based\n\\(\\text{Œº}_{3}\\).\\[\\beta_{1} = \\frac{\\mu_{3}^{2}}{\\mu_{2}^{3}}\\]Pronounced ‚Äòbeta one‚Äô\\(\\beta_{1}\\)= 0 means curve symmetrical. greater \nvalue \\(\\beta_{1}\\)skewed distribution. One serious\nlimitation \\(\\beta_{1}\\)tell direction \nskewness, .e., whether positive negative. Since\n\\(\\text{Œº}_{2}\\) always positive \\(\\mu_{3}^{2}\\) positive,\n\\(\\beta_{1}\\) positive always. drawback removed \ncalculating\\(\\text{Œ≥}_{1}\\), called Karl Pearson‚Äôs\\(\\text{ Œ≥}_{1}\\),\npronounced ‚Äògamma one.‚Äô\\[\\gamma_{1} = \\sqrt{\\beta_{1}} = \\frac{\\mu_{3}}{\\mu_{2}^{3}}\\]\\(\\mu_{3}\\) positive \\(\\gamma_{1}\\) positive, \\(\\mu_{3}\\) \nnegative \\(\\gamma_{1}\\) negative\\(\\gamma_{1}\\)= 0 means curve symmetrical.\\(\\gamma_{1}\\)= 0 means curve symmetrical.\\(\\gamma_{1}\\) > 0 means curve positively skewed.\\(\\gamma_{1}\\) > 0 means curve positively skewed.\\(\\gamma_{1}\\)< 0 means curve negatively skewed.\\(\\gamma_{1}\\)< 0 means curve negatively skewed.Example 6.1 given , skewness can examined \\(\\mu_{3}\\)= 0.226\\(\\mu_{2}\\)= 3.123\\(\\beta_{1} = \\frac{\\mu_{3}^{2}}{\\mu_{2}^{3}}\\) =\n\\(\\frac{\\left( 0.226 \\right)^{2}}{\\left( 3.123 \\right)^{3}} = \\ \\frac{0.051}{30.46} = 0.0016\\)\\(\\gamma_{1} = \\sqrt{\\beta_{1}} = \\ \\sqrt{0.0016} = + 0.04\\)Since \\(\\mu_{3}\\) positive \\(\\gamma_{1}\\)positive. Since\n\\(\\gamma_{1}\\)slightly greater 0, distribution slightly\nskewed right.","code":""},{"path":"skewness-and-kurtosis.html","id":"kurtosis","chapter":"6 Skewness and Kurtosis","heading":"6.3 Kurtosis","text":"Kurtosis another measure shape distribution. Whereas\nskewness measures lack symmetry frequency curve \ndistribution, kurtosis measure relative peakedness \nfrequency curve. Various frequency curves can divided three\ncategories depending upon shape peak.\nFigure 6.8: Three categories frequency curves depending upon shape peak\nKurtosis refers degree flatness peakedness curve. \nmeasured relative peakedness normal curve. normal curve considered mesokurtic. curve \npeaked normal curve, called leptokurtic. curve \nflat-topped normal curve, called platykurtic.condition peakedness (leptokurtic) flatness (platykurtic) \ncalled kurtosis excess.Measure kurtosis given ‚Äòbeta two‚Äô given Karl Pearson\\(\\beta_{2} = \\frac{\\mu_{4}}{\\mu_{2}^{2}}\\)\\(\\mu_{4}\\) 4th central moment, \\(\\mu_{2}\\) 2nd\ncentral moment\\(\\beta_{2}\\)= 3 means curve mesokurtic.\\(\\beta_{2}\\)= 3 means curve mesokurtic.\\(\\beta_{2}\\) > 3 means curve leptokurtic.\\(\\beta_{2}\\) > 3 means curve leptokurtic.\\(\\beta_{2}\\)< 3 means curve platykurtic.\\(\\beta_{2}\\)< 3 means curve platykurtic.Another measure kurtosis gamma two, \\(\\gamma_{2} = \\beta_{2} - 3\\ \\)\\(\\gamma_{2}\\)= 0 means curve mesokurtic.\\(\\gamma_{2}\\)= 0 means curve mesokurtic.\\(\\gamma_{2}\\) > 0 means curve leptokurtic.\\(\\gamma_{2}\\) > 0 means curve leptokurtic.\\(\\gamma_{2}\\)< 0 means curve platykurtic.\\(\\gamma_{2}\\)< 0 means curve platykurtic.Example 6.1 given , kurtosis can examined followsMean,\\(\\ \\overline{x}\\ \\)= 61.40\\(\\mu_{2}\\) = 3.123 (calculation shown previous example)\\(\\mu_{4} = \\frac{\\sum_{= 1}^{N}{f_{}\\left( x_{} - \\overline{x} \\right)^{4}}}{N} = \\frac{4312.747}{187} = 23.062\\)\\(\\beta_{2} = \\frac{\\mu_{4}}{\\mu_{2}^{2}} = \\frac{23.062}{\\left( 3.123 \\right)^{2}} = 2.364\\)\\(\\beta_{2}\\) 2.364, close 3, distribution can considered\nslightly platykurtic close symmetric.can verify frequency curve Example 6.1 , can seen\nslightly right tailed (positively skewed)\nFigure 6.9: frequency curve Example 6.1\n","code":""},{"path":"measures-of-association.html","id":"measures-of-association","chapter":"7 Measures of Association","heading":"7 Measures of Association","text":"","code":""},{"path":"measures-of-association.html","id":"scatter-diagram","chapter":"7 Measures of Association","heading":"7.1 Scatter Diagram","text":"Consider two variables x y, use scatter diagram \ninvestigate whether relation two variables. \nvariables x y plotted along X-axis Y-axis\nrespectively X-Y plane graph sheet resultant diagram \ndots known scatter diagram. scatter diagram can\nsay whether association X Y.Example 7.1: Consider data Sepal length (x) Sepal width (y) Iris setosa.\nFigure 7.1: Scatter diagram data Example 7.1\n","code":""},{"path":"measures-of-association.html","id":"correlation","chapter":"7 Measures of Association","heading":"7.2 Correlation","text":"Correlation statistical technique used analyzing behaviour\ntwo variables. correlation measures degree \ncloseness linear relationship two variables \nnumerical magnitude.Correlation measure enable us compare linear relationship\ntwo variables using single number. two \nquantities vary related manner movements one tend \naccompanied movements , said \ncorrelated.","code":""},{"path":"measures-of-association.html","id":"positive-correlation","chapter":"7 Measures of Association","heading":"7.2.1 Positive correlation","text":"Positive correlation relationship two variables \nvariables move direction. positive correlation\nexists one variable decreases variable decreases, \none variable increases increases.Examples positive correlation: consider two variables x yThe time spend running treadmill [Running time\n(x)], calories burn [calories burned (y)].\ncan see x increases y also increasesThe time spend running treadmill [Running time\n(x)], calories burn [calories burned (y)].\ncan see x increases y also increasesShorter people [Height (x)] smaller shoe sizes [shoe size\n(y)]. can see x decreases y also decreases.Shorter people [Height (x)] smaller shoe sizes [shoe size\n(y)]. can see x decreases y also decreases.hours spend direct sunlight [Hours sunlight\n(x)], tan [melanin content(y)]. can\nsee x increases y also increasesThe hours spend direct sunlight [Hours sunlight\n(x)], tan [melanin content(y)]. can\nsee x increases y also increasesAs temperature goes [Temperature (x)], ice cream sales\n[sales (y)], also go .temperature goes [Temperature (x)], ice cream sales\n[sales (y)], also go .","code":""},{"path":"measures-of-association.html","id":"negative-correlation","chapter":"7 Measures of Association","heading":"7.2.2 Negative correlation","text":"Negative correlation relationship two variables \none variable increases decreases, vice versa.Examples negative correlation: consider two variables x yA student many absences [.¬†days absent (x)] \ndecrease grades [grades (x)]. can see x\nincreases y decreases.student many absences [.¬†days absent (x)] \ndecrease grades [grades (x)]. can see x\nincreases y decreases.weather gets colder [Average monthly temperature (x)], air\nconditioning costs decrease [Price .C (y)].weather gets colder [Average monthly temperature (x)], air\nconditioning costs decrease [Price .C (y)].chicken increases age [chicken age (x)], number \neggs produces [.¬†eggs produced (y)] decreases.chicken increases age [chicken age (x)], number \neggs produces [.¬†eggs produced (y)] decreases.car decreases speed [average car speed(x)], travel time\n(y) destination increases.car decreases speed [average car speed(x)], travel time\n(y) destination increases.","code":""},{"path":"measures-of-association.html","id":"other-types-of-correlation","chapter":"7 Measures of Association","heading":"7.3 Other types of correlation","text":"","code":""},{"path":"measures-of-association.html","id":"simple-and-multiple","chapter":"7 Measures of Association","heading":"7.3.1 Simple and Multiple","text":"simple correlation relationship\nconfined two variables . multiple correlation \nrelationship two variables judged.","code":""},{"path":"measures-of-association.html","id":"partial-and-total","chapter":"7 Measures of Association","heading":"7.3.2 Partial and total","text":"two types correlations multiple\ncorrelation analysis.partial correlation relationship two variables \nexamined eliminating linear effect correlated\nvariables.total correlation based relevant variables.Correlation measures linear relationship variables","code":""},{"path":"measures-of-association.html","id":"linear-relationship","chapter":"7 Measures of Association","heading":"7.4 Linear relationship","text":"linear relationship (linear association)\nstatistical term used describe straight-line relationship\nvariables.Linear relationships can expressed either graphical format \nvariable plotted X-Y plane gives straight line relation\ntwo variables (consider x y) can expressed \nequation straight line (y = + bx) (**clear\ndiscuss regression)Example 7.2: Consider following example ice cream salesThe local ice cream shop keeps track much ice cream sell\nversus temperature day; figures last\n12 days:rest discussion using example .","code":""},{"path":"measures-of-association.html","id":"methods-of-measurement-of-correlation","chapter":"7 Measures of Association","heading":"7.5 Methods of measurement of correlation","text":"","code":""},{"path":"measures-of-association.html","id":"scatter-diagram-or-graphic-method","chapter":"7 Measures of Association","heading":"7.5.1 Scatter diagram or Graphic method","text":"\nFigure 7.2: Scatter plot Example 7.2\nFigure 7.2 can see linear association two variables .e.\ntemperature ice cream sales. can shown using line \n. clear temperature increases sales increases,\nindicating positive correlation.\nFigure 7.3: Linear relationship variables\nexample clear scatter diagram gives idea \nlinear association variables, can also used graphical\ntool see whether correlation present .Perfect Correlation: change value one\nvariable, value variable changed fixed\nproportion correlation said perfect\ncorrelation. perfect correlation, points lie \nstraight line. scatter diagram Example 7.2, can see \nperfect linear relationship points exactly \nline, points scattered form still \ndirection (positive).Direction correlation can identified using scatter diagram shown Figure 7.4\nFigure 7.4: Scatter plot nature relationship\n","code":""},{"path":"measures-of-association.html","id":"karl-pearsons-coefficient-of-correlation-r","chapter":"7 Measures of Association","heading":"7.5.2 Karl Pearson‚Äôs coefficient of Correlation (r)","text":"important widely used measure correlation. \nmeasure intensity degree linear relationship two\nvariables developed Karl Pearson, British Biometrician - known\nPearson‚Äôs Correlation coefficient denoted r\nexpressed ratio covariance product standard deviations two variables.","code":""},{"path":"measures-of-association.html","id":"covariance","chapter":"7 Measures of Association","heading":"7.5.2.1 Covariance","text":"Covariance measure joint linear variability two\nvariables. Consider two variables x y n observations\n, covariance given formulaCovariance (x,y) =\n\\(\\frac{1}{n}\\sum_{= 1}^{n}{\\left( x_{} - \\overline{x} \\right)\\left( y_{} - \\overline{y} \\right)}\\)covariance = 0 joint variability linear\nrelationship. unit covariance product units \ntwo variables.Covariance two variables x y denoted Cov(x, y).\nCovariance measure used find correlation coefficient.correlation coefficient two variables (x y) \ncalculated \\[r=\\frac{cov(x,y)}{sd(x)sd(y)}\\]sd. standard deviation.\\[r = \\frac{\\frac{1}{n}\\sum_{= 1}^{n}{\\left( x_{} - \\overline{x} \\right)\\left( y_{} - \\overline{y} \\right)}}{\\sqrt{\\frac{1}{n}\\sum_{= 1}^{n}\\left( x_{} - \\overline{x} \\right)^{2}\\frac{1}{n}\\sum_{= 1}^{n}\\left( y_{} - \\overline{y} \\right)^{2}}}\\]\n#### Properties correlation coefficient (r)pure number independent origin scale \nunits observations.pure number independent origin scale \nunits observations.always lies ‚àí1 +1 (absolute value exceed\nunity). ‚àí1 ‚â§ r ‚â§ +1It always lies ‚àí1 +1 (absolute value exceed\nunity). ‚àí1 ‚â§ r ‚â§ +1r = +1, indicates perfect positive correlation. r = ‚àí1,\nindicates perfect negative correlation. r = 0, indicates \ncorrelation.r = +1, indicates perfect positive correlation. r = ‚àí1,\nindicates perfect negative correlation. r = 0, indicates \ncorrelation.correlation zero linear relationship\nvariables.correlation zero linear relationship\nvariables.meaningful relation variables value\ncorrelation obtained also meaningless. (example \nfertilizer price increases, Kohili‚Äôs batting average also increases,\nknow practical relationship variables,\nstill may get correlation measure called spurious\ncorrelation)meaningful relation variables value\ncorrelation obtained also meaningless. (example \nfertilizer price increases, Kohili‚Äôs batting average also increases,\nknow practical relationship variables,\nstill may get correlation measure called spurious\ncorrelation)Simplified formula computation correlation coefficient can\nderived modifying formulaA Simplified formula computation correlation coefficient can\nderived modifying formula\\[r = \\frac{n\\left( \\sum_{= 1}^{n}{x_{}y_{}} \\right) - \\sum_{= 1}^{n}{x_{}\\sum_{= 1}^{n}y_{}}}{\\sqrt{\\left\\lbrack n\\sum_{= 1}^{n}{x_{}^{2} - \\left( \\sum_{= 1}^{n}x_{} \\right)^{2}} \\right\\rbrack\\left\\lbrack n\\sum_{= 1}^{n}{y_{}^{2} - \\left( \\sum_{= 1}^{n}y_{} \\right)^{2}} \\right\\rbrack}}\\]Example 7.3: Consider Example 7.2 ice cream sales; find\ncorrelation coefficient (r)n =12\\[mean,\\overline{x} = \\ \\frac{224.1}{12} = 18.675\\]\\[mean,\\overline{y} = \\ \\frac{4829}{12} = 402.416\\]Cov (x,y) =\n\\(\\frac{1}{n}\\sum_{= 1}^{n}{\\left( x_{} - \\overline{x} \\right)\\left( y_{} - \\overline{y} \\right)}\\)\\(\\sum_{= 1}^{12}{\\left( x_{} - \\overline{x} \\right)\\left( y_{} - \\overline{y} \\right)} = 5325.03\\)Cov (x,y) = \\(\\frac{5325.03}{12} = 443.752\\)\\[Standard\\ deviation,\\ S.D\\left( x \\right) = \\ \\sqrt{\\frac{1}{n}\\sum_{= 1}^{n}\\left( x_{} - \\overline{x} \\right)^{2}} = \\sqrt{\\frac{176.983}{12}} = 3.840\\]\\[Standard\\ deviation,\\ S.D\\left( y \\right) = \\ \\sqrt{\\frac{1}{n}\\sum_{= 1}^{n}\\left( y_{} - \\overline{y} \\right)^{2}} = \\sqrt{\\frac{174754.9}{12}} = 120.676\\]\\(r = \\frac{443.752}{3.840\\  \\times 120.676} = 0.95751\\), indicates\nstrong positive correlation","code":""},{"path":"measures-of-association.html","id":"spearmans-rank-order-correlation-coefficient-œÅ","chapter":"7 Measures of Association","heading":"7.5.3 Spearman‚Äôs Rank order correlation coefficient (œÅ)","text":"Spearman correlation evaluates monotonic relationship \ntwo continuous ordinal variables.Note: monotonic relation?monotonic relationship, variables tend move \nrelative direction, necessarily constant rate. linear\nrelationship, variables move direction constant\nrate.Linear relationship monotonic monotonic relations \nlinear. can see plots better understanding.\nFigure 7.5: Linear Monotonic relationship\nSpearman correlation coefficient based ranked values \nvariable rather raw data. spearman correlation\nmeasures monotonic relationship variables, pearsons\ncorrelation coefficient measures linear relationship . use\nSpearman‚Äôs correlation coefficient data must ordinal,\ninterval ratio scale.two cases calculating œÅ. One case tied rank\ntied rank","code":""},{"path":"measures-of-association.html","id":"no-tied-rank-case","chapter":"7 Measures of Association","heading":"7.5.3.1 No tied rank case","text":"two distinct observations \nvalue, thus given rank, said tiedThe formula Spearman rank correlation coefficient \ntied ranks :\\[\\rho = 1 - \\frac{6\\sum_{= 1}^{n}d_{}^{2}}{n\\left( n^{2} - 1 \\right)}\\]\\(d_{}\\) difference ranks ith pair \nobservationExample 7.4: Calculation Spearman‚Äôs rank correlation \ntied rank explained step step using example belowThe scores nine students physics math follows:Physics: 35, 23, 47, 17, 10, 43, 9, 6, 28Mathematics: 30, 33, 45, 23, 8, 49, 12, 4, 31Compute student‚Äôs ranks two subjects compute Spearman\nrank correlation.Step 1: Find ranks individual subject. Rank scores\ngreatest smallest; assign rank 1 highest score, 2 \nnext highest :MathematicsStep 2: Add column d, data. d difference\nranks. example, first student‚Äôs physics rank 3 \nmath rank 5, difference -2. next column, square \nd values.MathematicsStep 4: Sum (add ) d2 values. 4 + 4 + 1 + 0 + 1 +\n1 + 1 + 0 + 0 = 12. ‚Äôll need formula (\n\\(\\sum_{= 1}^{n}d_{}^{2}\\) just ‚Äúsum d2values, n=\n9‚Äù).Step 5: Insert values formula.\\[\\rho = 1 - \\frac{6\\sum_{= 1}^{n}d_{}^{2}}{n\\left( n^{2} - 1 \\right)}\\]\\[\\rho = 1 - \\frac{6 \\times 12}{9\\left( 81 - 1 \\right)} = 0.90\\]Spearman‚Äôs Rank Correlation set data 0.9.Spearman‚Äôs Rank Correlation also lies ‚àí1 +1 always. ‚àí1 ‚â§ œÅ\n‚â§+1","code":""},{"path":"measures-of-association.html","id":"tied-rank-case","chapter":"7 Measures of Association","heading":"7.5.3.2 Tied rank case","text":"Calculation Spearman‚Äôs rank correlation \ntied rank explained step step using example belowExample 7.5: scores nine students physics mathematics follows:PhysicsMathematicsStep 1: Consider marks Physics, ranked usualPhysicsYou can see value 23 repeated, may equal ranks, \naverage two ranks 5 6 given ;\n\\(\\left( \\frac{5 + 6}{2} \\right)\\ \\)= 5.5PhysicsSimilarly marks mathematics can see 33 repeated thrice.MathematicsMathematicsYou can see value 33 repeated thrice, average three\nranks 3, 4 5 given \\(\\left( \\frac{3 + 4 + 5}{3} \\right)\\ \\)= 4MathematicsStep 2: Change formula\\[\\rho = 1 - \\frac{6\\left( \\sum_{= 1}^{n}d_{}^{2} + T_{x} + T_{y} \\right)}{n\\left( n^{2} - 1 \\right)}\\]m individuals tied (rank), s sets\nranks X- series ,\n\\(T_{x} = \\ \\frac{1}{12}\\sum_{= 1}^{s}{m_{}\\left( m_{}^{2} - 1 \\right)}\\)example marks Physics (x) two 23 values tied\ntherefore m = 2; since one set s =1\\(T_{x} = \\ \\frac{1}{12}\\left( 2 \\times (2^{2} - 1 \\right)\\) = 0.5If w individuals tied (rank), s‚Äô sets\nranks Y- series ,\n\\(T_{y} = \\ \\frac{1}{12}\\sum_{= 1}^{s'}{w_{}\\left( w_{}^{2} - 1 \\right)}\\)example marks Mathematics (y) three 33 values tied\ntherefore w = 3; since one set s =1\\(T_{y} = \\ \\frac{1}{12}\\left( 3 \\times (3^{2} - 1 \\right)\\) = 2Step 2: Calculate d use formulaPhysicsMathematics\\(\\rho = 1 - \\frac{6\\left( \\sum_{= 1}^{n}d_{}^{2} + T_{x} + T_{y} \\right)}{n\\left( n^{2} - 1 \\right)} = 1 - \\frac{6 \\times \\left( 44.5 + 0.5 + 2 \\right)}{9\\left( 9^{2} - 1 \\right)} = \\ 1 - \\frac{282}{720}\\)\n= 0.60834","code":""},{"path":"measures-of-association.html","id":"kendalls-rank-correlation-coefficient-œÑ","chapter":"7 Measures of Association","heading":"7.5.4 Kendall‚Äôs Rank Correlation Coefficient (œÑ)","text":"Kendall‚Äôs rank correlation coefficient also known Kendall‚Äôs Tau \ncoefficient concordance. lies 0 1, 0 ‚â§ œÑ ‚â§ 1. \nseveral sets ranks , can used test association.k sets rankings may determine association among\nusing Kendall‚Äôs coefficient Concordance (œÑ). \nmeasure useful study reliability scorings made \nnumber Judges.Arrange data table row representing ranks\nassigned (judge), say, n number objects. Let \nk number sets rankings object given k judges. \nKendall‚Äôs coefficient concordance œÑ computed \\[\\tau = \\frac{12\\left\\lbrack \\sum_{= 1}^{n}{R_{}^{2} - \\frac{\\left( \\sum_{= 1}^{n}R_{} \\right)^{2}}{n}} \\right\\rbrack}{k^{2}n\\left( n^{2} - 1 \\right)}\\]Example 7.6: crop production competition, 10 entries farmers\nranked agricultural scientists (judges). Find degree \nagreement among scientist competition result given .Solution:k = number judges = 4n = number farmers =10\\(\\left( \\sum_{= 1}^{10}R_{} \\right)^{2}\\ \\)= (220)2 = 48400\\(\\sum_{= 1}^{10}R_{}^{2}\\) = 5900\\[\\tau = \\frac{12\\left\\lbrack \\sum_{= 1}^{n}{R_{}^{2} - \\frac{\\left( \\sum_{= 1}^{n}R_{} \\right)^{2}}{n}} \\right\\rbrack}{k^{2}n\\left( n^{2} - 1 \\right)}\\]=\\(\\tau = \\frac{12\\left\\lbrack 5900 - \\frac{48400}{10} \\right\\rbrack}{16 \\times 10\\left( 100 - 1 \\right)}\\)\n= 0.803Since \\(\\tau\\) nearly equal 1, ranks given judges almost\n*************************************************","code":""},{"path":"regression-analysis.html","id":"regression-analysis","chapter":"8 Regression Analysis","heading":"8 Regression Analysis","text":"Regression analysis method using observations (data records)\nquantify relationship target variable also referred \ndependent variable, set independent variables.","code":""},{"path":"regression-analysis.html","id":"definition","chapter":"8 Regression Analysis","heading":"8.1 Definition","text":"Regression analysis mathematical measure \naverage relationship two variables terms \noriginal units data","code":""},{"path":"regression-analysis.html","id":"simple-regression","chapter":"8 Regression Analysis","heading":"8.2 Simple regression","text":"two variables involved; Regression\ncan defined functional relationship two variables,\none may represent cause may represent effect. \nvariable representing cause known independent variable \ndenoted ‚ÄòX.‚Äô variable ‚ÄòX‚Äô also known predictor variable,\nregressor explanatory variable. variable representing effect \nknown dependent variable denoted Y. example consider\nyield fertilizer dose, yield can considered dependent\nvariable (Y) fertilizer dose can considered independent\nvariable (X).","code":""},{"path":"regression-analysis.html","id":"two-types-of-variables","chapter":"8 Regression Analysis","heading":"8.3 Two types of variables","text":"regression analysis \nvariable whose values need predicted (Y) called dependent variable variable used prediction (X) called\nindependent variable.two independent variables present regression\ncalled Multiple Regression. two variables present\ncalled simple regression.","code":""},{"path":"regression-analysis.html","id":"detailed-explanation","chapter":"8 Regression Analysis","heading":"8.4 Detailed explanation","text":"Correlation statistical measure determines degree \nassociation two variables. Regression hand side describes\nindependent variable numerically related dependent\nvariable.Regression can simply defined technique fitting best line \nline best fit estimate value one variable basis \nanother variable. Now best line? line best fit?explaining , consider example Ice cream sales:Example 8.1: local ice cream shop keeps track much ice\ncream sell versus temperature day; \nfigures last 12 days:can use regression analysis answer following questionsWhat Ice cream sales temperature 20o Celsius?functional form relationship Temperature Ice\ncream sales?\nFigure 8.1: Scatter diagram data Example 8.1\ncan draw line denote functional relationship temperature sales\nFigure 8.2: lines drawn show functional relationship\ncan see shown can draw number lines, \nbest fit line?can say best fit line line passes \npoints distance point line minimum. Using\nregression technique easily draw line. proceeding\nknow concept error residuals.","code":""},{"path":"regression-analysis.html","id":"error-and-residual","chapter":"8 Regression Analysis","heading":"8.5 Error and residual","text":"error difference observed value true value\n(true value unobserved population mean population \nsample observations taken). residual difference\nobserved value predicted value (model\n[fitted line]). Error measured residual can ; \nresidual considered estimate error.\nFigure 8.3: Error depicted best fit line\ndistance observation (ei) fitted line can \nconsidered residual (error). Best fit line can obtained \nminimizing distance. can achieved using mathematical\ntechnique ‚Äúprinciple least squares.‚Äù","code":""},{"path":"regression-analysis.html","id":"straight-lines","chapter":"8 Regression Analysis","heading":"8.6 Straight lines","text":"straight line simplest figure geometry.Mathematical equation straight line Y= + bX.Two important features line slope intercept. \nY-intercept, intercept line y-value point\ncrosses y-axis. b slope line, \nnumber measures \"steepness. change Y \nunit change X along line. regression b called \nregression coefficientIntercept ()\nFigure 8.4: Intercept line\nSlope (b)\nFigure 8.5: Slope line\nb can considered finger print line; \nvalues can easily identify line.now problem simple, find line best, estimate &\nb, error ei observation minimized. \nuse method least squares.","code":""},{"path":"regression-analysis.html","id":"method-of-least-squares","chapter":"8 Regression Analysis","heading":"8.7 Method of least squares","text":"considering error term ei; equation straight line isyi=+bxi+ei;ei ith error term corresponding yi, \n=1,2,...,nLine best fit can obtained estimating b \nminimizing error sum ‚ÄôŒ£ei‚Äô. theorem Œ£ei =0; \nb estimated minimising Œ£ei 2","code":""},{"path":"regression-analysis.html","id":"principle-of-least-squares","chapter":"8 Regression Analysis","heading":"8.8 Principle of least squares","text":"statistical method used determine\nline best fit minimizing ¬†sum squares error term\nŒ£ei 2yi=+bxi+ei;ei = yi ‚Äì (+bxi)ei2 = {yi ‚Äì (+bxi)}2Œ£ ei2 = Œ£ {yi ‚Äì (+bxi)}2Œ£ ei2 called error sum squares. minimizing\nerror sum squares, hence name principle least squares.want minimize, E = Œ£ ei2 = Œ£ {yi ‚Äì\n(+bxi)}2i.e. need find b E minimumE can minimized taking derivative respect \nb equating zero. get two equations,\nequations termed normal equations solving \nnormal equations give formula b.discussing calculation part . taking derivatives \nget two equations (Normal equations) :\\[\\sum_{= 1}^{n}{y_{} = n\\mathbf{} + \\mathbf{b}\\sum_{= 1}^{n}x_{}}\\]\\[\\sum_{= 1}^{n}{y_{}x_{} = \\mathbf{}\\sum_{= 1}^{n}x_{} + \\mathbf{b}\\sum_{= 1}^{n}x_{}^{2}}\\]solving equations getRegression coefficient, b =\n\\(\\frac{\\sum_{= 1}^{n}{y_{}x_{} - \\frac{\\sum_{= 1}^{n}{y_{}\\sum_{= 1}^{n}x_{}}}{n}}}{\\sum_{= 1}^{n}x_{}^{2} - \\frac{\\left( \\sum_{= 1}^{n}x_{} \\right)^{2}}{n}}\\)=\\(\\frac{cov(x,y)}{var(x)}\\)\\[\\mathbf{b =}\\frac{\\mathbf{cov(x,y)}}{\\mathbf{var(x)}}\n\\]\\[\\mathbf{=}\\overline{\\mathbf{y}}\\mathbf{- b}\\overline{\\mathbf{x}}\\]\\(\\overline{y}\\) = mean y; \\(\\overline{x}\\) = mean x","code":""},{"path":"regression-analysis.html","id":"two-lines-of-regression","chapter":"8 Regression Analysis","heading":"8.9 Two lines of regression","text":"two lines regression- y x x y.Regression y xConsider two variables x y, considering y \ndependent variable x independent variable equation\n:y = + bxThis used predict unknown value variable y value \nvariable x known. Usually b denoted byx\\[\\mathbf{b}_{\\mathbf{\\text{yx}}}\\mathbf{=}\\frac{\\mathbf{cov(x,y)}}{\\mathbf{var(x)}}\\]Consider Example 8.1; considering ice cream sales dependent variable\ntemperature independent variable\nFigure 8.6: Scatter diagram data Example 8.1\nRegression x yConsider two variables x y, considering x \ndependent variable y independent variable equation\n:x= c + ; c intercept m \nslopeThis used predict unknown value variable x value \nvariable y known. Usually b denoted bxy\\[\\mathbf{b}_{\\mathbf{\\text{xy}}}\\mathbf{=}\\frac{\\mathbf{cov(x,y)}}{\\mathbf{var(y)}}\\]Consider Example 8.1; considering temperature dependent variable \nice cream sales independent variable\nFigure 8.7: Scatter diagram data Example 8.1\ncan see regression different. depends \nexperimenter choose dependent independent variable. \nexample evident considering temperature dependent variable\nmeaningless, .e. usefulness predicting\ntemperature based ice cream sales?. selection dependent \nindependent variable entirely discretion experimenter based \nobjective study.","code":""},{"path":"regression-analysis.html","id":"assumptions-of-regression","chapter":"8 Regression Analysis","heading":"8.10 Assumptions of Regression","text":"y dependent variable x independent variable\nthenThe x‚Äôs non-random fixed constantsThe x‚Äôs non-random fixed constantsAt fixed value x corresponding values y \nnormal distribution mean.fixed value x corresponding values y \nnormal distribution mean.given x, variance y .given x, variance y .values y observed different levels x completely\nindependent.values y observed different levels x completely\nindependent.","code":""},{"path":"regression-analysis.html","id":"properties-of-regression-coefficients","chapter":"8 Regression Analysis","heading":"8.11 Properties of Regression coefficients","text":"correlation coefficient x y geometric\nmean two regression coefficients byx bxy\\[r = \\sqrt{b_{\\text{yx}}b_{\\text{xy}}}\\]Regression coefficients independent change origin \nscale.Regression coefficients independent change origin \nscale.one regression coefficient greater unit, \nmust less unit vice versa. .e. \nregression coefficients can less unity \ngreater unity, .e. byx >1 bxy <1\nbxy >1, byx <1.one regression coefficient greater unit, \nmust less unit vice versa. .e. \nregression coefficients can less unity \ngreater unity, .e. byx >1 bxy <1\nbxy >1, byx <1.Also one regression coefficient positive must \npositive (case correlation coefficient positive) \none regression coefficient negative must negative\n(case correlation coefficient negative).Also one regression coefficient positive must \npositive (case correlation coefficient positive) \none regression coefficient negative must negative\n(case correlation coefficient negative).","code":""},{"path":"regression-analysis.html","id":"uses-of-regression","chapter":"8 Regression Analysis","heading":"8.12 Uses of Regression","text":"Prediction: regression analysis useful predicting \nvalue one variable given value another variable. \npredictions useful difficult expensive measure\ndependent variable, Y.Identify strength relationship: regression might used\nidentify strength effect independent variable(s)\ndependent variable. Like strength relationship \ndose effect, sales marketing spending, age income.Forecast effects impact changes: , regression\nanalysis helps us understand much dependent variable changes\nchange one independent variables. typical question\n, \"much additional sales income get additional 1000\nspent marketingPredicts trends future values: regression analysis can \nused predict trend future values, like ‚Äúprice \ngold 6 months?‚Äù","code":""},{"path":"regression-analysis.html","id":"example-problem","chapter":"8 Regression Analysis","heading":"8.13 Example problem","text":"Now consider example 8.1 answer questionsWhat functional form relationship Temperature \nIce cream sales?functional form relationship Temperature \nIce cream sales?Ice cream sales temperature 20o Celsius?Ice cream sales temperature 20o Celsius?SolutionFit model considering Ice cream sales dependent variable (y)\ntemperature independent variable (x). Fitting model means\nestimating b using equation.Fit model considering Ice cream sales dependent variable (y)\ntemperature independent variable (x). Fitting model means\nestimating b using equation.fitting model put 20 x value get \npredicted y valueAfter fitting model put 20 x value get \npredicted y valueModel: y = +bxTemperatureSalesn =12\\[mean,\\overline{x} = \\ \\frac{224.1}{12} = 18.675\\]\\[mean,\\overline{y} = \\ \\frac{4829}{12} = 402.416\\]Cov (x,y) =\n\\(\\frac{1}{n}\\sum_{= 1}^{n}{\\left( x_{} - \\overline{x} \\right)\\left( y_{} - \\overline{y} \\right)}\\)\\(\\sum_{= 1}^{12}{\\left( x_{} - \\overline{x} \\right)\\left( y_{} - \\overline{y} \\right)} = 5325.03\\)Cov (x,y) = \\(\\frac{5325.03}{12} = 443.752\\)\\[variance\\ \\ x,\\ var\\left( x \\right) = \\ \\frac{1}{n}\\sum_{= 1}^{n}\\left( x_{} - \\overline{x} \\right)^{2} = \\frac{176.983}{12} = 14.7485\\]\\[\\mathbf{b =}\\frac{\\mathbf{cov(x,y)}}{\\mathbf{var(x)}}\\]\\[\\mathbf{b =}\\frac{443.752}{14.7485}\\mathbf{=}30.088\\]\\[\\mathbf{=}\\overline{\\mathbf{y}}\\mathbf{- b}\\overline{\\mathbf{x}}\\]\\[\\mathbf{=}402.416 - 30.088\\left( 18.675 \\right) = \\  - 159.477\\]model \\[y = \\  - 159.477 + 30.088x\\]\\[Ice\\ cream\\ sales = \\  - 159.477 + 30.088(Temperature)\\]Ice cream sales temperature 20o Celsius\\[x = 20\\]\\(y = \\  - 159.477 + 30.088(20)\\) = 442.283So predicted ice cream sales 20o Celsius $442.283**************************************************************","code":""},{"path":"probability.html","id":"probability","chapter":"9 Probability","heading":"9 Probability","text":"Many events can‚Äôt predicted total certainty. best can say likely happen, using idea probability.","code":""},{"path":"probability.html","id":"tossing-a-coin","chapter":"9 Probability","heading":"9.1 Tossing a Coin","text":"coin tossed, two possible outcomes:heads (H) orheads (H) ortails (T)tails (T)say probability coin landing¬†H¬†¬†¬Ω probability coin landing¬†T¬†¬†¬Ω","code":""},{"path":"probability.html","id":"throwing-dice","chapter":"9 Probability","heading":"9.2 Throwing Dice","text":"single¬†die¬†thrown, six possible\noutcomes: 1, 2, 3, 4, 5, 6. probability getting one ¬†\\(\\frac{1}{6}\\)\nFigure 9.1: Image dice (plural)\n","code":""},{"path":"probability.html","id":"playing-cards","chapter":"9 Probability","heading":"9.3 Playing cards","text":"standard deck playing cards consists 52 cards divided 4 suits (Spades, Hearts, Diamonds, Clubs) 13 cards \nFigure 9.2: Image spade symbol\nSpades : - 13 cards, include 9 numbered cards 2 10 picture cards Ace, King, Queen, Jack\nFigure 9.3: Image hearts symbol\nHearts : - 13 cards\nFigure 9.4: Image diamond symbol\nDiamonds :- 13 cards\nFigure 9.5: Image clubs symbol\nClubs :- 13 cardsRed cards:- 26 cards Black cards:- 26 cards","code":""},{"path":"probability.html","id":"probability-1","chapter":"9 Probability","heading":"9.4 Probability","text":"general:Probability event happening =\n\\(\\frac{\\text{Number ways can happen}}{\\text{Total  number outcomes}}\\)","code":""},{"path":"probability.html","id":"example-1","chapter":"9 Probability","heading":"Example 1","text":"chances rolling \"4\" dieNumber ways can happen: 1¬†(1 face \"4\" )Total number outcomes: 6¬†(6 faces altogether)probability =¬†\\(\\frac{1}{6}\\)","code":""},{"path":"probability.html","id":"example-2","chapter":"9 Probability","heading":"Example 2","text":"5 marbles bag: 4 blue, 1 red. probability blue marble gets picked?Number ways can happen: 4¬†(4 blues)Total number outcomes: 5¬†(5 marbles total)probability =¬†\\(\\frac{4}{5}\\) = 0.8","code":""},{"path":"probability.html","id":"must-learn-definitions","chapter":"9 Probability","heading":"Must learn definitions","text":"Random experiment: random experiment experiment process outcome predicted certainty.Eg: Tossing coin; Tossing coin five times; Choosing card deck\ncards; Tossing die.Sample space: sample space (denoted S) random experiment set possible outcomes.Eg: Throwing coin generates sample space; S={H,T},Throwing die: S= {1,2,3,4,5,6}Sample point: Just one possible outcomes. Eg: heads, 5 Clubs cards. 6 different sample points sample space throwing \ndie.Exercise1: Check yourselfIf die tossedWhat sample space?probability getting 1?probability obtaining even number?probability getting 7?\nFigure 9.6: Sample space throwing die\n","code":""},{"path":"probability.html","id":"event","chapter":"9 Probability","heading":"9.4.1 Event","text":"One outcomes random experimentAn event can just one outcome:Getting Tail tossing coinGetting Tail tossing coinRolling \"5\"Rolling \"5\"event can include one outcome:Choosing \"King\" deck cards (4 Kings)Choosing \"King\" deck cards (4 Kings)Rolling \"even number\" (2, 4 6)Rolling \"even number\" (2, 4 6)","code":""},{"path":"probability.html","id":"example","chapter":"9 Probability","heading":"Example","text":"Ram wants see many times \"double\" (dice number) comes throwing 2 dice.Sample Space possible Outcomes (36 Sample Points):{1,1} {1,2} {1,3} {1,4} ... {6,3} {6,4} {6,5} {6,6}Event Ram looking \"double\", dice number. made 6 Sample Points:{1,1} {2,2} {3,3} {4,4} {5,5} {6,6}","code":""},{"path":"probability.html","id":"types-of-events","chapter":"9 Probability","heading":"9.4.1.1 Types of Events","text":"Independent EventsEvents can \"Independent\", meaning event affected events.Eg: toss coin comes \"Heads\" three times. chance next toss also \"Head\"?chance simply¬†¬Ω¬†(0.5) just like toss coin. Past affect current toss.Dependent EventsBut events can \"dependent\", means can affected previous events. taking one card deck less\ncards available, probabilities change!look chances getting King deck cardsFor 1st card chance drawing King 4 52But 2nd card:1st card King, 2nd card less likely \nKing, 3 51 cards left Kings.1st card King, 2nd card slightly \nlikely King, 4 51 cards left King.NoteReplacement: put card back drawing chances change, events independent.Without Replacement: chances change, events dependent.Mutually Exclusive EventsMutually Exclusive means get events time. \neither one , bothExamples:Turning left right Mutually Exclusive (\ntime)Turning left right Mutually Exclusive (\ntime)Heads Tails Mutually ExclusiveHeads Tails Mutually ExclusiveKings Aces Mutually ExclusiveKings Aces Mutually ExclusiveWhat Mutually ExclusiveKings Hearts Mutually Exclusive, can King Hearts!Exhaustive EventsA set events called exhaustive events together make \nentire sample space.exampleSample space tossing die \\(S\\)= {1, 2, 3, 4, 5, 6}theEvent : getting even number; {2, 4, 6}Event B: getting odd number; {1, 3, 5}exhaustive events together makes entire sample space.Equally likely eventsEqually likely events events theoretical\nprobability occurring.example: Tossing coinEvent : getting headEvent B: getting tailBoth events equal probability occurring; events termed equally likely events","code":""},{"path":"probability.html","id":"definition-of-probability","chapter":"9 Probability","heading":"9.5 Definition of Probability","text":"","code":""},{"path":"probability.html","id":"mathematical-definition","chapter":"9 Probability","heading":"9.5.1 Mathematical Definition","text":"experiment \\(n\\) exhaustive, mutually exclusive equally likely outcomes, \\(m\\) outcomes favourable happening event \\(E\\), probability \\(p\\) happening E given \\[P\\left( E \\right) = p = \\ \\frac{m}{n}\\]\\(p\\) termed probability success.","code":""},{"path":"probability.html","id":"example-3","chapter":"9 Probability","heading":"Example","text":"coin tossed, two possible outcomes Heads Tails. Outcomes exhaustive, mutually exclusive equally likely.Consider event \\(E\\) : getting headProbability event \\(E\\), \\(p(E)\\) denoted \\(p\\)\\(p\\) given definition :\\(m\\) = number outcomes favourable happening event \\(E\\) = 1\\(n\\) = number outcomes (Head Tail) = 2\\[P\\left( E \\right) = p = \\ \\frac{m}{n}\\]\\[P\\left( E \\right) = p = \\ \\frac{1}{2}\\].e. probability getting Head ¬Ωdefinition following limitationsWhat happen outcomes equally likely. example\ntossing biased die.happen outcomes equally likely. example\ntossing biased die.Probability defined total cases ‚Äòn‚Äô unknown \ntends infinity. example; probability raining\ntomorrow?Probability defined total cases ‚Äòn‚Äô unknown \ntends infinity. example; probability raining\ntomorrow?overcome limitations, definitions given","code":""},{"path":"probability.html","id":"statistical-definition","chapter":"9 Probability","heading":"9.5.2 Statistical Definition","text":"probability 'p' happening E given \\[P\\left( E \\right) = \\lim_{n \\rightarrow \\infty}\\frac{m}{n}\\]\\(n\\) number times process (e.g., tossing die) \nperformed tends infinity, \\(m\\) number times \noutcome ‚Äò\\(E\\)‚Äô happens.definition also limitationsIn cases, experiment never practice carried \n.cases, experiment never practice carried \n.leaves open question large \\(n\\) get\ngood approximation.leaves open question large \\(n\\) get\ngood approximation.overcome limitations, another approach probability \nintroduced Russian mathematician .N. Kolmogorov. approach \nprecise definition given, instead certain axioms postulates \nprobability calculations based.","code":""},{"path":"probability.html","id":"axiomatic-approach","chapter":"9 Probability","heading":"9.5.3 Axiomatic Approach","text":"Whole field probability theory based following three axiomsProbability event, P (\\(E\\)) lies 0 1.\n\\(0 \\leq P(E) \\leq 1\\)Probability event, P (\\(E\\)) lies 0 1.\n\\(0 \\leq P(E) \\leq 1\\)Probability entire sample space 1. \n\\(P\\left( S \\right) = 1\\)Probability entire sample space 1. \n\\(P\\left( S \\right) = 1\\)B mutually exclusive events probability occurrence either B denoted \\(P(\\cup B)\\) shall given \\(P\\left( \\cup B \\right) = P\\left( \\right) + P(B)\\)B mutually exclusive events probability occurrence either B denoted \\(P(\\cup B)\\) shall given \\(P\\left( \\cup B \\right) = P\\left( \\right) + P(B)\\)","code":""},{"path":"probability.html","id":"some-interesting-facts-on-probability","chapter":"9 Probability","heading":"Some interesting facts on probability","text":"Probability \\(p\\) happening event known probability success probability \\(q\\)‚Äô \nnon-happening event probability failure.Probability \\(p\\) happening event known probability success probability \\(q\\)‚Äô \nnon-happening event probability failure.\\(p\\) well \\(q\\) non-negative exceed unity. .e., 0 ‚â§ \\(p\\) ‚â§ 1 0 ‚â§ \\(q\\) ‚â§ 1. Thus, probability occurrence event lies 0 1[including 0 1]\\(p\\) well \\(q\\) non-negative exceed unity. .e., 0 ‚â§ \\(p\\) ‚â§ 1 0 ‚â§ \\(q\\) ‚â§ 1. Thus, probability occurrence event lies 0 1[including 0 1]Probability impossible event 0 sure event 1. \\(p()\\) = 1, event certainly going happen \\(p()\\) = 0, event certainly going happen.Probability impossible event 0 sure event 1. \\(p()\\) = 1, event certainly going happen \\(p()\\) = 0, event certainly going happen.number (\\(m\\)) favorable outcomes event greater total number outcomes (\\(n\\)).number (\\(m\\)) favorable outcomes event greater total number outcomes (\\(n\\)).\nFigure 9.7: Sample space throwing die\n","code":""},{"path":"probability.html","id":"additional-problems","chapter":"9 Probability","heading":"Additional Problems","text":"simultaneous toss two coins, find probability () getting 2 heads. (ii) exactly 1 head ?SolutionHere, possible outcomes HH, HT, TH, TT. .e., Total number possible outcomes = 4.() Number outcomes favorable event (2 heads) = 1 (.e.,HH). .e.\\(p\\)(2 heads) = 1/4 .(ii) Now event consisting exactly one head two favourable cases, namely HT TH\\(p\\)(exactly one head) = 2 /4 = 1/ 2In single throw two dice, probability sum 9?SolutionThe number possible outcomes 6 √ó 6 = 36.1,1 1,2 1,3 1,4 1,5 1.62,1 2,2 2,3 2,4 2,5 2,63,1 3,2 3,3 3,4 3,5 3,64,1 4,2 4,3 4,4 4,5 4,65,1 5,2 5,3 5,4 5,5 5,66,1 6,2 6,3 6,4 6,5 6,6Event : sum 9four outcomes sum 9, (5,4), (6,3), (3,6), (4,5)Probability (sum 9) = 4/36= 1/9From bag containing 10 red, 4 blue 6 black balls, ball drawn random. probability drawing () red ball? (ii) blue ball? (iii) black ball?20 balls . , total number possible outcomes 20() Number red balls = 10,\\(p\\)(getting red ball ) = 10/20 = ¬Ω(ii) Number blue balls = 4\\(p\\)(getting blue ball ) = 4/20 = 1/5(iii) Number balls black = 14\\(p\\)(black ball ) = 14/20 = 7/10","code":""},{"path":"probability.html","id":"event-relations","chapter":"9 Probability","heading":"9.6 Event relations","text":"Consider tossing die. event getting even number, sample points 2, 4 6 favorable event . remaining sample points 1, 3 5 favorable event . Therefore, occur event occur. experiment, outcomes favorable event \ncalled complement denoted '' Ac","code":""},{"path":"probability.html","id":"event-a-or-b","chapter":"9 Probability","heading":"9.6.1 Event A or B","text":"Denoted (\\(\\cup\\) B), spelled union BLet us consider example throwing die. event getting\nmultiple 2 B another event getting multiple 3. \noutcomes 2, 4 6 favourable event outcomes 3 \n6 favourable event B..e.= {2, 4, 6}B= {3, 6}Íì¥ B = { 2, 3, 4,6}, event getting even number B another\nevent getting odd number, thenA = { 2, 4, 6 }B = { 1, 3, 5 }Íì¥ B = {1, 2, 3, 4,5,6}","code":""},{"path":"probability.html","id":"event-a-and-b","chapter":"9 Probability","heading":"9.6.2 Event A and B","text":"Denoted (Íìµ B) spelled intersection B. throwing die event getting multiple 2 B event getting multiple 3. outcomes favorable 2, 4, 6 outcomes favorable B 3, 6. 6 present B Íìµ B = 6\nFigure 9.8: Venn diagram showing intersection\n","code":""},{"path":"probability.html","id":"additive-law-of-probability","chapter":"9 Probability","heading":"9.7 Additive law of Probability","text":"two events B sample space S,\\(p\\)(Íì¥B) = \\(p\\)()+\\(p\\)(B) ‚àí \\(p\\)(ÍìµB)mutually exclusive case \\(p\\)P(ÍìµB)=0; case \\(p\\)(Íì¥B )= \\(p\\)()+\\(p\\)(B ).","code":""},{"path":"probability.html","id":"example-4","chapter":"9 Probability","heading":"Example","text":"card drawn well-shuffled deck 52 cards. probability either spade king?denotes event drawing 'spade card'. B denotes events drawing 'king' respectively. event consists 13 sample points, whereas event B consists 4 sample points.\\(p\\)()= 13/52\\(p\\)(B)= 4/52\\(p\\)( ÍìµB) = 1/52\\(p\\)(Íì¥B)= \\(p\\)()+\\(p\\)(B) ‚àí \\(p\\)(ÍìµB) = 13/52+4/52-1/52 = 4/13In single throw two dice, find probability total 9 11.Let events = total 9 B= total 11.Events mutually exclusive Íìµ B = 0Now \\(p\\)() = \\(p\\) [(3, 6), (4, 5), (5, 4), (6, 3)] = 4 /36\\(p\\)(B) = \\(p\\)[ (5, 6), (6, 5)] = 2 /36Thus, \\(p\\)( Íì¥B) = 4 /36 +2/36 =6/36=1/6","code":""},{"path":"probability.html","id":"multiplication-law-of-probability","chapter":"9 Probability","heading":"9.8 Multiplication law of probability","text":"B independent events, \\(p\\)(ÍìµB) = \\(p\\)(). \\(p\\)(B)called Multiplication law probabilityA die tossed twice. Find probability number greater 4 throw.Let us denote , event 'number greater 4' first throw. B event 'number greater 4' second throw. Clearly B independent events. first throw, two outcomes, namely, 5 6 favourable event .‚à¥ \\(p\\)() =2/6 = 1/3Similarly second throw, two outcomes, namely, 5 6 favourable event .‚à¥ \\(p\\)(B) = 2/6 = 1/3Hence, \\(p\\)(B) = \\(p\\)(ÍìµB) = \\(p\\)().\\(p\\)(B) = 1 /3 √ó1 /3 = 1/9","code":""},{"path":"probability.html","id":"probability-using-combinations","chapter":"9 Probability","heading":"Probability using combinations","text":"Knowledge combinations can applied find total number possible outcomes.nCr\\(= \\frac{n!}{r!(n - 1)!}\\)example\n3C2\\(= \\frac{3!}{2!(3 - 2)!} = \\frac{3 \\times 2 \\times 1}{2 \\times 1(1)} = 3\\)Now let us see example used probabilityA bag contains 3 red, 6 white 7 blue balls. probability two balls drawn white blue?Total number balls = 3 + 6 + 7 = 16Out 16 balls, 2 balls can drawn 16C2 waysi.e. 16C2 = 120.6 white balls, 1 ball can drawn 6C1 ways 7 blue balls, one can drawn 7C1 ways. Since former case associated later case, therefore total number favorable cases 6C1 √ó 7C1Therefore required probability= (6C1 √ó 7C1) / 16C2 = 42/120 = 7/20Find probability getting red balls, bag containing 5 red 4 black balls, two balls drawnTotal number balls = 9Out 9 balls, 2 balls can drawn 9C2 waysNo ways red balls can taken = 5C2Hence \\(p\\)(red balls ) = 5C2 / 9C2 = 5/18","code":""},{"path":"probability.html","id":"answer","chapter":"9 Probability","heading":"9.9 Answers of exercise 1","text":"{1, 2, 3, 4, 5, 6}{1, 2, 3, 4, 5, 6}1/61/63/6 = 1/23/6 = 1/200********************************************************","code":""},{"path":"probability-distributions.html","id":"probability-distributions","chapter":"10 Probability Distributions","heading":"10 Probability Distributions","text":"","code":""},{"path":"probability-distributions.html","id":"random-experiment","chapter":"10 Probability Distributions","heading":"10.1 Random experiment","text":"random experiment experiment \nprocess outcome predicted certainty. \nsample space (denoted S) random experiment set \npossible outcomes.Example: Tossing coin, Throwing die etc","code":""},{"path":"probability-distributions.html","id":"random-variable","chapter":"10 Probability Distributions","heading":"10.2 Random variable","text":"Random Variable set possible\nvalues random experiment. Random variable usually denoted ‚Äò\\(X\\)‚Äô\nFigure 10.1: Tossing coin\nRandom Variable whole set values take values, randomly. like Algebra Variable, Algebra variable, like X, unknown value. Random Variable different.Probability random variable can represented \\(p(X = x)\\) \\(p(x)\\).Small letter \\(x\\) denotes value taken random variable \\(X\\).example throwing die onceHere can define random variable interest. Defining random variable like:Let \\(X\\) number appearing throwing dice ; \\(x\\) = {1, 2, 3, 4, 5, 6}. random variable \\(X\\) can take values shown . case equally likely, probability anyone 1/6. , \\(p(X = x)\\) = \\(p(x)\\) =1/6Let \\(X\\) number appearing throwing dice ; \\(x\\) = {1, 2, 3, 4, 5, 6}. random variable \\(X\\) can take values shown . case equally likely, probability anyone 1/6. , \\(p(X = x)\\) = \\(p(x)\\) =1/6Let \\(X\\) even number appearing throwing dice ; \\(X\\) = {2, 4, 6}. random variable \\(X\\) can take values shown . \\(p(X = x)\\) = \\(p(x)\\) = 3/6Let \\(X\\) even number appearing throwing dice ; \\(X\\) = {2, 4, 6}. random variable \\(X\\) can take values shown . \\(p(X = x)\\) = \\(p(x)\\) = 3/6","code":""},{"path":"probability-distributions.html","id":"probability-distributions-1","chapter":"10 Probability Distributions","heading":"10.3 Probability distributions","text":"probability distribution list possible outcomes random variable along corresponding probability values.Example: - Tossing coin 3 timesDefining random variable:Let X number heads appearing throwing dice\ncase 0 heads, 1, 2 3 heads, sample space \\(X\\) = {0, 1, 2, 3} equally likely.total 8 possible cases tossing coin three times shown table \\(p(X = x)\\) = \\(\\frac{: \\ \\ times\\ X\\ takes\\ value\\ x}{8}\\)\\(p(X = 3)\\) = 1/8; \\(p(X = 2)\\) = 3/8; \\(p(X = 1)\\) = 3/8; \\(p(X = 0)\\) = 1/8A¬†probability distribution list possible outcomes random variable along corresponding probability values.Table shows probability distribution.example discrete probability distribution \\(X\\) takes discrete values. \\(x\\) takes continuous values, termed continuous probability distribution.","code":""},{"path":"probability-distributions.html","id":"probability-mass-function","chapter":"10 Probability Distributions","heading":"10.4 Probability mass function","text":"use probability function describe discrete probability distribution, call probability mass function (commonly abbreviated p.m.f). probability mass function, returns probability outcome. Therefore, probability mass function written : \\(p(x)\\) = \\(p(X = x)\\). variable \\(X\\) discrete nature.","code":""},{"path":"probability-distributions.html","id":"probability-density-function","chapter":"10 Probability Distributions","heading":"10.5 Probability density function","text":"use probability function describe continuous probability distribution, call probability density function (commonly abbreviated p.d.f).","code":""},{"path":"probability-distributions.html","id":"expected-value-of-a-random-variable","chapter":"10 Probability Distributions","heading":"10.6 Expected value of a random variable","text":"Expected value exactly might think means. return can expect kind action. ¬†expected value¬†¬†random variable long-run average value repetitions ¬†experiment¬†represents.¬†example, expected value rolling six-sided¬†die 3.5, average numbers come\n3.5 number rolls approaches infinity. Expected value random variable \\(X\\) denoted \\(E(X)\\).\nformula calculating Expected Value random variable ¬†multiple probabilities isE(\\(X\\)) = \\(\\sum_{= 1}^{\\infty}xp(x)\\) (Discrete Case)E(\\(X\\)) = \\(\\sum_{= 1}^{\\infty}xp(x)\\) (Discrete Case)E(\\(X\\)) = \\(\\int_{- \\infty}^{\\infty}{x p(x)\\ \\text{dx }}\\)\n(continuous case); \\(- \\infty \\leq x \\leq \\infty\\)E(\\(X\\)) = \\(\\int_{- \\infty}^{\\infty}{x p(x)\\ \\text{dx }}\\)\n(continuous case); \\(- \\infty \\leq x \\leq \\infty\\)random variable \\(X\\) lies \\({-\\infty}\\) \\({+\\infty}\\)","code":""},{"path":"probability-distributions.html","id":"example-5","chapter":"10 Probability Distributions","heading":"Example","text":"Find Expected value \\(X\\) tossing single unfair dieSolution:E(\\(X\\)) = \\(\\sum_{= 1}^{6}xp(x)\\)\n= 0.1+0.2+0.3+0.4+0.5+3 = 4.5Find E(X) following case ()","code":""},{"path":"probability-distributions.html","id":"discrete-probability-distributions","chapter":"10 Probability Distributions","heading":"10.7 Discrete probability distributions","text":"seen ¬†probability distribution¬†list possible outcomes random variable along corresponding probability values. represented table. convenient can expressed equation. value x given can calculate corresponding probability equation. several discrete distributions depending situations. discussion limited following discrete distributions.Bernoulli distributionBernoulli distributionBinomial distributionBinomial distributionPoisson distributionPoisson distribution","code":""},{"path":"probability-distributions.html","id":"bernoulli-distribution","chapter":"10 Probability Distributions","heading":"10.7.1 Bernoulli distribution","text":"Bernoulli distribution ¬†discrete probability distribution. distribution applies random experiment two outcomes (usually called ‚ÄúSuccess‚Äù ‚ÄúFailure‚Äù).example tossing coin two outcomes can termed success failure experimenterSuccess: getting headFailure: getting tailThe probability mass function distribution \\(p(X = x)\\) = \\(p(x)\\) = \\(p\\)\\(x\\)\\((1-p)\\)\\(1-x\\), \\(X\\) takes two values = 0,1The¬†expected value¬†random variable, \\(X\\), Bernoulli distribution : E(\\(X\\)) = \\(p\\) ¬†variance¬†Bernoulli random variable : var(\\(X\\)) = \\(p(1 - p)\\).","code":""},{"path":"probability-distributions.html","id":"example-6","chapter":"10 Probability Distributions","heading":"Example","text":"Find probability assuming Bernoulli distribution \nbiased coin probability success (getting head) \\(p\\) = 0.4Let \\(X\\) random variable takes value 0 getting tail\n(failure) takes value 1 getting head (success). using \nequationp(\\(X\\) = \\(x\\)) = p(\\(X\\)) = p\\(X\\)\\((1-p)\\)\\(1-x\\)P(\\(X\\) = 0) = (0.4)0(1-0.4)1 =0.6P(\\(X\\) = 1) = (0.4)1(1-0.4)0 =0.4A¬†Bernoulli trial¬†one simplest experiments can conduct\nprobability statistics. ‚Äôs experiment can one\ntwo possible outcomes. example, ‚ÄúYes‚Äù ‚Äú‚Äù ‚ÄúHeads‚Äù \n‚ÄúTails.‚Äù","code":""},{"path":"probability-distributions.html","id":"binomial-distribution","chapter":"10 Probability Distributions","heading":"10.7.2 Binomial distribution","text":"Binomial distribution can thought simply probability \nSUCCESS FAILURE outcome experiment survey repeated\nmultiple times; .e. Binomial distribution happens, Bernoulli\ntrial repeated \\(n\\) number times. binomial type \ndistribution two possible outcomes (prefix ‚Äúbi‚Äù means two,\ntwice). example coin toss repeated 5 times, random\nvariable, \\(X\\) = : heads follow binomial distribution \\(n\\)\n= 5.Binomial distributions must also meet following three criteria:number observations trials fixed. (\\(n\\))number observations trials fixed. (\\(n\\))observation trial ¬†independentEach observation trial ¬†independentThe¬†probability success¬†(tails, heads, fail pass) ¬†exactly ¬†one trial another (\\(p\\))¬†probability success¬†(tails, heads, fail pass) ¬†exactly ¬†one trial another (\\(p\\))probability mass function distribution \\(p(x)\\) = \\(n\\)\\(c\\)\\(x\\)\\(p\\)\\(x\\)\\(q\\)\\(n-x\\) = \\(\\frac{n!}{\\left( n - x \\right)!x!\\ }\\) p\\(x\\)\\(q\\)\\(n-x\\)x takes values = 0,1,2,..., \\(n\\)\\(n\\)= number trials\\(x\\)= number success desired\\(p\\)= probability getting success one trial\\(q\\) = \\(1-p\\) = probability getting failure one trialE(\\(X\\)) = \\(np\\)V(\\(X\\)) = \\(npq\\); \\(n\\) \\(p\\) important parameters binomial\ndistribution.Mean binomial distribution \\(np\\) variance \\(npq\\)","code":""},{"path":"probability-distributions.html","id":"example-7","chapter":"10 Probability Distributions","heading":"Example","text":"coin tossed 10 times. probability \ngetting exactly 6 heads?,\\(n\\) = 10\\(x\\) = 6\\(p\\) = ¬Ω\\(q\\) = \\(1-p\\) = ¬Ωfind \\(p(X=6)\\); using formula \\(p(X=x)\\) \\(=\\) \\(n\\)\\(c\\)\\(x\\)\\(p\\)\\(x\\)\\(q\\)\\(n-x\\)\\(p(X=6)\\) = 10\\(c\\)6\\(\\left( \\frac{1}{2} \\right)^{6}\\left( \\frac{1}{2} \\right)^{10 - 6}\\)=\n0.2050","code":""},{"path":"probability-distributions.html","id":"poisson-distribution","chapter":"10 Probability Distributions","heading":"10.7.3 Poisson distribution","text":"Discovered French Mathematician Simeon Denis Poisson (1781\n-1840). developed describe number times gambler \nwin rarely won game chance large number tries, .e.¬†Poisson\ndistribution deals rare events.Poisson distribution first applied study number death \nhorse kicking Prussian army.applications examples Poisson distribution usedPest incidencePest incidenceBirth defects genetic mutationsBirth defects genetic mutationsRare diseasesRare diseasesCar accidentsCar accidentsTraffic flow ideal gap distanceTraffic flow ideal gap distanceNumber typing errors pageNumber typing errors pageHairs found McDonald's hamburgersHairs found McDonald's hamburgersSpread endangered animal AfricaSpread endangered animal AfricaFailure machine one monthFailure machine one monthA random variable \\(X\\) said follow Poisson distribution; \nassumes non-negative values probability mass function given\n:\\[p\\left( X = x \\right) = \\frac{e^{- \\lambda}.\\lambda^{x}}{x!}\\]\\(x\\) = 0,1,2,‚Ä¶ ., ‚àû,\\(e\\) = 2.7183.\\(Œª\\) : Average number successes occurring given time interval \nregion Poisson distributionIt discrete distribution single parameter ŒªThe mean variance Poisson distribution \nequal ¬†\\(Œª\\)","code":""},{"path":"probability-distributions.html","id":"example-8","chapter":"10 Probability Distributions","heading":"Example","text":"average number homes sold Realty company 2\nhomes per day. Assuming Poisson distribution probability\nexactly 3 homes sold tomorrow?Solution:\\(Œª\\) = 2; since 2 homes sold per day, average.\\(x\\) = 3; since want find probability 3 homes sold\ntomorrow.\\(e\\) = 2.71828; since e constant equal approximately 2.71828.\\[p\\left( X = x \\right) = \\frac{e^{- \\lambda}.\\lambda^{x}}{x!}\\]\\(p(X=3)\\) = \\(\\ \\frac{{2.71828}^{- 2}{\\  \\times \\ 2}^{3}}{3!}\\)\\(p(X = 3)\\) = 0.180","code":""},{"path":"probability-distributions.html","id":"questions","chapter":"10 Probability Distributions","heading":"Questions","text":"random variable X follows Poisson distribution mean 3.4, find \\(p(X = 6)\\)random variable X follows Poisson distribution mean 3.4, find \\(p(X = 6)\\)number industrial injuries per working week particular factory known follow Poisson distribution mean 0.5. Find probability particular week :number industrial injuries per working week particular factory known follow Poisson distribution mean 0.5. Find probability particular week :() Less 2 accidents [Hint: p(X<2) = p(X = 0) + p(X = 1)](ii) 2 accidents [Hint: p(X >2) = 1-{p(X = 0) + p(X = 1)\n+ p(X =2)}]company known past experience 3% bulbs produced defective. Assuming Poisson distribution find probability getting following sample 100 bulbs:\n[Hint: ¬†Œª = n √ó p = 100 √ó 0.03]\ndefective [Hint: let X number defectives; x = 0]\n1 defective [Hint: x = 1]\n2 Defectives [Hint: x = 2]\n3 defectives[Hint: x = 3]\ncompany known past experience 3% bulbs produced defective. Assuming Poisson distribution find probability getting following sample 100 bulbs:\n[Hint: ¬†Œª = n √ó p = 100 √ó 0.03]defective [Hint: let X number defectives; x = 0]defective [Hint: let X number defectives; x = 0]1 defective [Hint: x = 1]1 defective [Hint: x = 1]2 Defectives [Hint: x = 2]2 Defectives [Hint: x = 2]3 defectives[Hint: x = 3]3 defectives[Hint: x = 3]Distributions Bernoulli, Binomial Poisson discussed far discrete distributions.","code":""},{"path":"probability-distributions.html","id":"continuous-probability-distributions","chapter":"10 Probability Distributions","heading":"10.8 Continuous probability distributions","text":"random variable X continuous, corresponding probability\ndistribution termed continuous probability distribution. \nseveral continuous distributions. discussion limited \nNormal distribution.","code":""},{"path":"probability-distributions.html","id":"normal-distribution","chapter":"10 Probability Distributions","heading":"10.8.1 Normal distribution","text":"normal distribution defined following probability density function (probability density function explained section)\\[f\\left( x \\right) = \\frac{1}{\\sqrt{2\\pi\\sigma}}e^{- \\frac{{(x - \\mu)}^{2}}{2\\sigma^{2}}}\\], \\(- \\infty < x < + \\infty\\) ; \\(Œº\\) population mean \\(œÉ\\)2 \nvariance, e = 2.718.random variable \\(X\\) follows normal distribution, write:\\(X\\)~\\(N\\)(\\(Œº\\), \\(œÉ\\)2)particular, normal distribution \\(Œº\\) = 0 \\(œÉ\\)2 = 1 called\nstandard normal distribution, denoted \\(X\\)~\\(N\\)(0,1).","code":""},{"path":"probability-distributions.html","id":"properties-of-normal-distribution","chapter":"10 Probability Distributions","heading":"Properties of Normal distribution","text":"normal distribution frequently used among probability laws. normal distribution can found many practical problemsIf plot density \\(f(x)\\) \\(x\\) graph bell shaped always\nFigure 10.2: Normal distribution curve\nMany things closely follow Normal Distribution:Yield cropsYield cropsheights peopleheights peoplesize things produced machinessize things produced machineserrors measurementserrors measurementsblood pressureblood pressuremarks testmarks testThe Normal Distribution :mean = median = modeMean located centre curve. mean = median = mode, \nlocate towards centre\nFigure 10.3: Mean=Median=Mode normal distribution\nNormal distribution symmetric centre, 50% values less mean 50% greater mean\nFigure 10.4: Normal distribution symmetric distribution\n","code":""},{"path":"probability-distributions.html","id":"standardisation-of-normal-distribution","chapter":"10 Probability Distributions","heading":"10.8.1.1 Standardisation of Normal distribution","text":"standard normal distribution special case normal\ndistribution mean zero standard deviation 1.distribution also known Z-distribution. value \nstandard normal distribution known standard score Z-score.standard score Z-score represents number standard deviations mean specific observation falls.convert value Standard Score (\"z-score\"):First subtract mean,First subtract mean,divide Standard DeviationThen divide Standard DeviationAnd called \"Standardizing\".\nFigure 10.5: Standardization Normal distribution\nExample: survey daily travel time results (minutes):\\(X\\): 26, 33, 65, 28, 34, 55, 25, 44, 50, 36, 26, 37, 43, 62, 35, 38, 45, 32, 28, 34Convert standard scores (Z-score).Mean 38.8 minutes, Standard Deviation 11.4First subtract mean observationFirst subtract mean observationThen divide Standard DeviationThen divide Standard Deviation\nFigure 10.6: Z score values X\n¬†z-score formula¬†using :\\[z = \\frac{x - \\mu}{\\sigma}\\]z \"z-score\" (Standard Score)z \"z-score\" (Standard Score)\\(x\\) value standardized\\(x\\) value standardized\\(Œº\\) ('mu\") mean\\(Œº\\) ('mu\") mean\\(œÉ\\) (\"sigma\") standard deviation\\(œÉ\\) (\"sigma\") standard deviation","code":""},{"path":"probability-distributions.html","id":"parameters-of-normal-distribution","chapter":"10 Probability Distributions","heading":"Parameters of Normal distribution","text":"probability distribution, parameters normal distribution define shape probabilities entirely. normal distribution two parameters, mean (\\(Œº\\)) standard deviation (\\(œÉ\\)). normal distribution just one form. Instead, shape changes based parameter values\nFigure 10.7: Shape changes normal distribution based different means\nStandard deviation:standard deviation measure variability. defines width normal distribution. determines far away mean values tend fall. represents typical distance observations average\nFigure 10.8: Shape changes normal distribution based different standard deviation\nnormally distributed data, standard deviation can used determine proportion values fall within \nspecified number standard deviations mean. example, \nnormal distribution, 68 % observation falls within +/- 1 standard\ndeviation mean. property called Area Property.","code":""},{"path":"probability-distributions.html","id":"area-property","chapter":"10 Probability Distributions","heading":"Area Property","text":"\nFigure 10.9: Area property normal distribution\nshort properties Normal distributionNormal distribution curve bell shapedNormal distribution curve bell shapedNormal distribution symmetric, skewed.Normal distribution symmetric, skewed.mean, median, mode equal.mean, median, mode equal.Half population less mean half greater\nmean.Half population less mean half greater\nmean.Area property allows determine proportion values \nfall within certain distances mean.Area property allows determine proportion values \nfall within certain distances mean.","code":""},{"path":"probability-distributions.html","id":"solved-example","chapter":"10 Probability Distributions","heading":"Solved example","text":"1. z-score value 27, given set mean 24, \nstandard deviation 2?SolutionTo find z-score need divide difference value,\n27, mean, 24, standard deviation set, 2.\\[z = \\frac{27 - 24}{2} = \\frac{3}{2} = 1.5\\]indicates 27 +1.5 standard deviations mean.Using z-value calculate probability; z-value tables etc \ndiscussed practical session.***********************************","code":""},{"path":"hypothesis-testing.html","id":"hypothesis-testing","chapter":"11 Hypothesis Testing","heading":"11 Hypothesis Testing","text":"Statistical analysis integral part scientific\ninvestigation. statistical analysis can conducted, researcher must generate guess, hypothesis going .process begins working hypothesis. Working hypothesis direct statement research idea. example, plant biologist may think plant height may affected applying different fertilizers. might say: \"Plants different fertilizers grow different heights\".","code":""},{"path":"hypothesis-testing.html","id":"the-falsification-principle","chapter":"11 Hypothesis Testing","heading":"The Falsification Principle","text":"falsification principle Proposed Karl Popper, way demarcating science non-science. suggests theory considered scientific must able tested proven false. example, hypothesis \"swans white,\" can falsified observing black swan. According Popper, science attempt disprove theory, rather attempt continually support theoretical hypotheses.","code":""},{"path":"hypothesis-testing.html","id":"null-hypothesis","chapter":"11 Hypothesis Testing","heading":"11.1 Null hypothesis","text":"considering Popperian Principle Falsification, need translate working hypothesis framework consisting two hypotheses. hypotheses termed Null hypothesis Alternative hypothesis. clear example .Null hypothesis hypothesis either rejected accepted based experiment.example biologist may state null hypothesis average height (mean height) plants different fertilizers .alternative hypothesis (biologist hopes show) average height (mean height) plants different fertilizers equal, .e. fertilizer treatments produced plants different mean heights.¬†Now experiment biologist may either reject null hypothesis\naccept . turn result acceptance rejection \nalternative hypothesis accordingly.finally concentrate either rejecting accepting null\nhypothesis.","code":""},{"path":"hypothesis-testing.html","id":"definitions","chapter":"11 Hypothesis Testing","heading":"Definitions","text":"Null hypothesis: statement 'effect' 'difference'.\" often symbolized H0. hypothesis researcher trying disprove.Alternative hypothesis: simply inverse, opposite, null hypothesis. often symbolized H1.","code":""},{"path":"hypothesis-testing.html","id":"example-9","chapter":"11 Hypothesis Testing","heading":"Example","text":"long ago, people believed world flat. research problem whether Earth flat?Null hypothesis, H0: Earth flat.Alternate hypothesis, H1: world round.Several scientists, including Copernicus, set disprove null hypothesis. eventually led rejection null acceptance alternate.","code":""},{"path":"hypothesis-testing.html","id":"state","chapter":"11 Hypothesis Testing","heading":"11.1.1 Stating hypothesis","text":"Problem 1: researcher thinks certain chemical applied twice week flowering fruit tree. Average fruit weight plant 8 kg.Let us see null hypothesis problem formulatedStep 1: Figure hypothesis problem. hypothesis usually hidden word problem, sometimes statement expect happen experiment.hypothesis question ‚Äúresearcher expects average fruit weight per plant 8 kg.‚ÄùŒº (pronounced ‚Äômu') denotes average yield say, null hypothesis can stated asH0: Œº = 8Step 2: alternative hypothesis. State, happen hypothesis doesn‚Äôt come true? average fruit weight equal 8 kg, one assumed possibility weight less 8 kg (assuming possibility chemical \nincrease yield). alternative hypothesis can stated asH1: Œº < 8But researcher doesn‚Äôt idea happen?Problem 2: researcher studying effect chemical plant yield. chemical used pesticide. wants prove chemical effect yield. chemical can dangerous may boost yield.Step 1: Figure hypothesis problem.hypothesis question ‚Äúresearcher expects change average yield application chemical 0‚ÄùŒº denotes ‚Äòchange‚Äô average yield chemical applicationNull hypothesis can stated asH0: Œº = 0Step 2: alternative hypothesis. Researcher idea whether chemical increase decrease yield. just wants prove chemical effect yield. alternative hypothesis beH1: Œº \\(\\mathbf{\\neq}\\) 0","code":""},{"path":"hypothesis-testing.html","id":"hypo","chapter":"11 Hypothesis Testing","heading":"11.2 Hypothesis testing problem","text":"hypothesis testing decision two alternatives, one called null hypothesis alternative hypothesis, must made. make decision, experiment performed. hypothesis testing acceptance rejection null hypothesis can based decision rule.Example: coin . need check whether coin biased unbiased. Unbiased means 50:50 chance landing head tail tossing .First formulate null hypothesis alternative hypothesis.coin unbiased probability obtaining head 0.5; .e. \\(p\\) = 0.5Therefore null hypothesis alternative hypothesis beH0: \\(p\\) = 0.5H1: \\(p\\) \\(\\mathbf{\\neq}\\) 0.5You designed experiment , toss coin 10 times note outcome. conducting experiment got outcome given belowIn hypothesis testing acceptance rejection null hypothesis can based decision rule. calculate test statistic sample (outcome experiment). Decision rule based statistic.Test statistic: Test statistic quantity computed values sample function sample values based decision made null hypothesis.example decision rule, might decide reject null hypothesis accept alternative hypothesis, 8 heads occur 10 tosses coin. , reject null hypothesis \\(p\\) \\(\\geq \\frac{8}{10} = 0.8\\).experiment testNumber heads = 8Number tosses = 10Test statistic calculated, \\(p\\) = 8/10 = 0.8So based decision rule reject null hypothesis, assume coin biased.Now example sake formulated decision rule. frame decision rule simply. lot factors need considered, like confident reject null hypothesis based sample observations taken (number tosses 10). discuss coming sections.","code":""},{"path":"hypothesis-testing.html","id":"errors-in-hypothesis-testing","chapter":"11 Hypothesis Testing","heading":"11.3 Errors in Hypothesis testing","text":"respect hypothesis testing two errors can occur\n:null hypothesis actually true decision based testing process concluded null hypothesis false rejectedThe null hypothesis actually true decision based testing process concluded null hypothesis false rejectedThe null hypothesis actually false testing process concludes true accepted.null hypothesis actually false testing process concludes true accepted.two errors called Type Type II errors.¬†Type error: Reject null hypothesis, actually trueType II error: Accept null hypothesis, actually false¬†","code":""},{"path":"hypothesis-testing.html","id":"level-of-significance-and-power-of-test","chapter":"11 Hypothesis Testing","heading":"11.4 Level of significance and power of test","text":"Level significance (Œ±)significance level, also denoted Œ± (alpha), probability rejecting null hypothesis true. .e. Level significance probability Type error.Power test (1- Œ≤)probability Type II error denoted Œ≤. ‚Äò1-Œ≤‚Äô termed power test. Power test probability rejecting null hypothesis false. Œ± Œ≤ plays role deciding decision rule hypothesis testing.Seriousness type type II errorsWhich error serious? understand interrelationship Type Type II error, determine error severe consequences situation, consider following example.medical researcher wants compare effectiveness two medications.Null hypothesis (H0): Œº1= Œº2The two medications equally effective.Alternative hypothesis (H1): Œº1‚â† Œº2The two medications equally effective.Type error occurs researcher rejects null hypothesis concludes two medications different , fact, .¬†much serious consequence.Type II error occurs researcher concludes medications , fact, different.\nerror potentially life-threatening, less-effective medication sold public instead effective one.Now example, diagnosing cancerNull hypothesis (H0): Patient cancerAlternative hypothesis (H1): Patient cancerA Type error occurs researcher rejects null hypothesis andconcludes patient cancer, actually healthyType II error occurs researcher concludes patient cancer cancerHere errors can serious consequencesDepending situation seriousness Type Type II error may change. cases Type severe, Type II may severe cases.Now let us look critically situation. try reduce Type error Type II error increase. try reduce Type II error Type increase. make decision, must identify error serious. commit Type 1 error, reject \nnull hypothesis true. false positive, like fire alarm rings fire. Type II error happens fail reject null true. false negative - like alarm fails sound fire.Let us return question error, Type Type II, worse.Consider person accused crime waiting judgement hanged.H0: innocentH1: hangedWhat judge makes Type error?\ninnocent hanged!!!!judge makes Type II error?criminal set free!!!course want let guilty person hook, people say sentencing innocent person punishment worse consequence. Hence, many textbooks instructors say Type (false positive) worse Type II (false\nnegative) error. assuming Type worse least worsening situation.practice, fix Type error selecting suitable probability Œ± experiment. reduce Type II error taking adequate sample size. Usually fix Œ± =0.05 0.01Note: exam question pops , error serious? Answer Type . honest answer - ‚Äòdepends‚Äô","code":""},{"path":"hypothesis-testing.html","id":"region-of-acceptance-and-rejection","chapter":"11 Hypothesis Testing","heading":"11.5 Region of acceptance and rejection","text":"test statistic calculate sample probability distribution. example consider coin tossing experiment discussed earlier. test statistic calculated person different person B, may get different outcomes performing experiment. particular value test statistic \nprobability. probability distribution test statistic termed sampling distribution test statistic.reject null hypothesis, test statistic falls particular area sampling distribution, area sampling distribution test statistic called region rejection. region sampling distribution test statistic called\nregion acceptance, test statistic falls area accept null hypothesis.\nFigure 11.1: Acceptance rejection region sampling distribution test statistic\nSize region rejection equal level significance = Œ±Size region acceptance equal = 1¬≠- Œ±The region rejection also known critical region. value test statistic reject null hypothesis called critical value.\nFigure 11.2: Critical value test statistic\n","code":""},{"path":"hypothesis-testing.html","id":"two-tailed-and-single-tailed-test","chapter":"11 Hypothesis Testing","heading":"11.6 Two tailed and single tailed test","text":"statistical test based two competing hypotheses: null hypothesis H0 alternative hypothesis H1. type alternative hypothesis H1 defines test one-tailed two-tailed. based alternative hypothesis type test determined.","code":""},{"path":"hypothesis-testing.html","id":"one-tailed-tests","chapter":"11 Hypothesis Testing","heading":"One-tailed tests","text":"Consider problem 1 section 11.1.1, alternative hypothesis stated asH1: Œº <8For alternative hypothesis reject null hypothesis test statistics falls towards left side sampling distribution, test left tailed test.H1: Œº > 8For alternative hypothesis reject null hypothesis test statistics falls towards right side sampling distribution, test right tailed test.Left tailed test: critical region towards left side sampling distribution test statistic\nFigure 11.3: Left tailed test: Critical region towards left side (Shown sampling distribution student t left tailed 20 degrees freedom)\nRight tailed test: critical region towards right side sampling distribution test statistic\nFigure 11.4: Right tailed test: Critical region towards right side (Shown sampling distribution student t right tailed 20 degrees freedom)\nTwo-tailed testsConsider problem 2 section 11.1.1, alternative hypothesisH1: Œº \\(\\mathbf{\\neq}\\) 0Consider another alternative hypothesisH1: Œº \\(\\mathbf{\\neq}\\) 8In cases critical region lies sides. Size side Œ±/2. Together total size Œ±\nFigure 11.5: Two tailed test: Critical region side\n","code":""},{"path":"hypothesis-testing.html","id":"decision-rule","chapter":"11 Hypothesis Testing","heading":"11.7 Decision rule","text":"calculation test statistic experiment, make decision null hypothesis?Decision rule largely determined level significance Œ±. good test one low probability committing Type error (.e., small Œ±) high power (1-Œ≤, high power).Power determined sample size experiment. Based Œ± select critical value test statistic, calculated value falls critical value reject null hypothesis (right tailed test). calculated value falls critical value \nreject null hypothesis (left tailed test). calculated value falls critical value sides, reject null hypothesis (two tailed test)","code":""},{"path":"hypothesis-testing.html","id":"an-example","chapter":"11 Hypothesis Testing","heading":"11.8 An example","text":"Consider example testing whether coin biased section 11.2Here going identify whether coin biased based just 10 tossing. (10 sample size).Let null hypothesis beH0: \\(p\\) = 0.5H1: \\(p\\) \\(\\neq\\) 0.5Let \\(X\\) number heads, let us see probability null hypothesis \\(X\\) take value 1 10.know binomial theorem:\\(p(X=x)\\) = \\(n\\)\\(c\\)\\(x\\)\\(p\\)\\(x\\)\\(q\\)\\(n-x\\) = \\(\\frac{n!}{\\left( n - x \\right)!x!\\ }\\) \\(p\\)\\(x\\)\\(q\\)\\(n-x\\)experiment n=10, null hypothesis true \\(p\\) = 0.5. probability distribution \\(X\\) , null hypothesis trueAbove distribution \\(X\\) can plotted ,\nFigure 11.6: Sampling distribution test statistic X\nŒ± level significance. experiment selected Œ± = 0.05. two tailed test critical value value \\(X\\), area Œ±/2 = 0.025. using probability distribution table can see area beyond \\(X\\) = 8 \\(X\\) = 2 approximately area 0.025. critical values\n\\(X\\) = 8 \\(X\\) = 2. means number heads 8 2 reject null hypothesis level significance Œ± =0.05.\nFigure 11.7: Probability distribution X critical region\nCommonly used test statistics \\(t\\), \\(F\\), \\(Z\\) œá2 (pronounced chi-square). Critical values test statistics already available tables.","code":""},{"path":"hypothesis-testing.html","id":"confidence-interval","chapter":"11 Hypothesis Testing","heading":"11.9 Confidence Interval","text":"rejecting null hypothesis level significance Œ±. Meaning can attach 100(1-Œ±)% confidence conclusion. rejecting null hypothesis level significance Œ±=0.05, 100(1-0.05)% .e. 95% confident result. Œ±=0.01 100(1-0.01)% .e. 99% confident\nresult. can also interpreted , can attach 95% confidence means, experiment repeated infinite number times, 95% chance get conclusion.","code":""},{"path":"hypothesis-testing.html","id":"steps-in-hypothesis-testing","chapter":"11 Hypothesis Testing","heading":"11.10 Steps in hypothesis testing","text":"Now conclusion following 7 steps hypothesis testingStep 1: State Null HypothesisStep 2: State Alternative HypothesisStep 3: Set level significance (Œ±)Step 4: Collect Data (experiment scientific methods)Step 5: Calculate test statisticStep 6: Identify critical region test statistic specified level significance (Œ±)Step 7: Compare test statistic critical value test statistic.Step 8: calculated value test statistic greater critical value test statistic reject null hypothesis 100(1 ‚Äì Œ± )% confidence. Otherwise state don‚Äôt enough evidence reject null hypothesis.Don‚Äôt panic, things take little time digest. gone much discussing concept detail. exam point view try answer followingWhat hypothesis?hypothesis?Define null alternative hypothesisDefine null alternative hypothesisDefine test statisticDefine test statisticTwo errors hypothesis testing, definition.Two errors hypothesis testing, definition.Define one-tailed two-tailed testDefine one-tailed two-tailed testDefine Critical region Critical valueDefine Critical region Critical valueDefine Power test, Level significanceDefine Power test, Level significanceWrite steps hypothesis testingWrite steps hypothesis testing","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
